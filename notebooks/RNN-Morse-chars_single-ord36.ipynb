{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with dit dah sequence recognition - 36 characters - element order prediction\n",
    "\n",
    "Builds on `RNN-Morse-chars-single-ddp06` with element order encoding, In `RNN-Morse-chars-single-ddp06` particularly when applyijng minmax on the raw predictions we noticed that it was not good at all at sorting the dits and dahs (everything went to the dah senses) but was good at predicting the element (dit or dah) relative position (order). Here we exploit this feature exclusively. The length of dits and dahs is roughly respected and the element (the \"on\" keying) is reinforced from the noisy original signal.\n",
    "\n",
    "Uses 5 element Morse encoding thus the 36 character alphabet.\n",
    "\n",
    "Training material will be generated as random Morse strings rather than actual characters to maintain enough diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create string\n",
    "\n",
    "Each character in the alphabet should happen a large enough number of times. As a rule of thumb we will take some multiple of the number of characters in the alphabet. If the multiplier is large enough the probability of each character appearance will be even over the alphabet. \n",
    "\n",
    "Seems to get better results looking at the gated graphs but procedural decision has to be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "\n",
    "morse_gen = MorseGen.Morse()\n",
    "alphabet = morse_gen.alphabet36\n",
    "print(132/len(alphabet))\n",
    "\n",
    "morse_cwss = MorseGen.get_morse_eles(nchars=132*5, nwords=27*5, max_elt=5)\n",
    "print(alphabet)\n",
    "print(len(morse_cwss), morse_cwss[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframe and extract envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 8000\n",
    "decim = 128\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*12*2) + 1\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/decim:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim_ord_morse(morse_cwss, samples_per_dit, decim, 5)\n",
    "env = label_df['env'].to_numpy()\n",
    "print(type(env), len(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_new_data(morse_gen, SNR_dB=-23, nchars=132, nwords=27, morse_cwss=None, max_elt=5):\n",
    "    decim = 128\n",
    "    if not morse_cwss:\n",
    "        morse_cwss = MorseGen.get_morse_eles(nchars=nchars, nwords=nwords, max_elt=max_elt)\n",
    "    print(len(morse_cwss), morse_cwss[0])\n",
    "    Fs = 8000\n",
    "    samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "    #n_prev = int((samples_per_dit/decim)*19) + 1 # number of samples to look back is slightly more than a \"O\" a word space (3*4+7=19)\n",
    "    #n_prev = int((samples_per_dit/decim)*23) + 1 # (4*4+7=23)\n",
    "    n_prev = int((samples_per_dit/decim)*27) + 1 # number of samples to look back is slightly more than a \"0\" a word space (5*4+7=27)\n",
    "    print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/decim:.2f}. Look back is {n_prev}.')\n",
    "    label_df = morse_gen.encode_df_decim_ord_morse(morse_cwss, samples_per_dit, decim, max_elt)\n",
    "    # extract the envelope\n",
    "    envelope = label_df['env'].to_numpy()\n",
    "    # remove the envelope\n",
    "    label_df.drop(columns=['env'], inplace=True)\n",
    "    SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "    SNR_linear *= 256 # Apply original FFT\n",
    "    print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "    t = np.linspace(0, len(envelope)-1, len(envelope))\n",
    "    power = np.sum(envelope**2)/len(envelope)\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(envelope))\n",
    "    # noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "    signal = (envelope + noise)**2\n",
    "    signal[signal > 1.0] = 1.0 # a bit crap ...\n",
    "    return envelope, signal, label_df, n_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "max_ele = morse_gen.max_ele(alphabet)\n",
    "envelope, signal, label_df, n_prev = get_new_data(morse_gen, SNR_dB=-17, morse_cwss=morse_cwss, max_elt=max_ele)\n",
    "\n",
    "# Show\n",
    "print(n_prev)\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "    \n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,4))\n",
    "plt.plot(signal[x0:x1]*0.7, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 1.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 1.0, label='chr', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 1.0, label='wrd')\n",
    "for i in range(max_ele):\n",
    "    plt.plot(label_df[x0:x1][f'e{i}']*0.9 + 2.0 + i, label=f'e{i}')\n",
    "plt.title(\"signal and labels\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader\n",
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MorsekeyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, morse_gen, device, SNR_dB=-23, nchars=132, nwords=27, morse_cwss=None, max_elt=5):\n",
    "        self.max_ele = max_elt\n",
    "        self.envelope, self.signal, self.label_df0, self.seq_len = get_new_data(morse_gen, SNR_dB=SNR_dB, morse_cwss=morse_cwss, max_elt=max_elt)\n",
    "        self.label_df = self.label_df0\n",
    "        self.X = torch.FloatTensor(self.signal).to(device)\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_envelope(self):\n",
    "        return self.envelope\n",
    "    \n",
    "    def get_signal(self):\n",
    "        return self.signal\n",
    "    \n",
    "    def get_X(self):\n",
    "        return self.X\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_labels0(self):\n",
    "        return self.label_df0\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len()\n",
    "    \n",
    "    def max_ele(self):\n",
    "        return self.max_ele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keying data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_chr_dataset = MorsekeyingDataset(morse_gen, device, -20, 132*5, 27*5, morse_cwss, max_ele)\n",
    "train_chr_loader = torch.utils.data.DataLoader(train_chr_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = train_chr_dataset.get_signal()\n",
    "envelope = train_chr_dataset.get_envelope()\n",
    "label_df = train_chr_dataset.get_labels()\n",
    "label_df0 = train_chr_dataset.get_labels0()\n",
    "\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,4))\n",
    "plt.plot(signal[x0:x1]*0.8, label=\"sig\", color=\"cornflowerblue\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 1.0, label='ele', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 1.0, label='chr', color=\"green\")\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 1.0, label='wrd', color=\"red\")\n",
    "for i in range(max_ele):\n",
    "    label_key = f'e{i}'\n",
    "    plt.plot(label_df[x0:x1][label_key]*0.9 + 2.0, label=label_key)\n",
    "plt.title(\"keying - signal and labels\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseBatchedLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "    \n",
    "    def _minmax(self, x):\n",
    "        x -= x.min(0)[0]\n",
    "        x /= x.max(0)[0]\n",
    "        \n",
    "    def _hardmax(self, x):\n",
    "        x /= x.sum()\n",
    "        \n",
    "    def _sqmax(self, x):\n",
    "        x = x**2\n",
    "        x /= x.sum()\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        #print(len(input_seq), input_seq.shape, input_seq.view(-1, 1, 1).shape)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(-1, 1, self.input_size), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        self._minmax(predictions[-1])\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )     \n",
    "    \n",
    "class MorseBatchedMultiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer1_size=6, output1_size=6, hidden_layer2_size=12, output_size=14):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer1_size = hidden_layer1_size\n",
    "        self.output1_size = output1_size\n",
    "        self.hidden_layer2_size = hidden_layer2_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=hidden_layer1_size)\n",
    "        self.linear1 = nn.Linear(hidden_layer1_size, output1_size)\n",
    "        self.hidden1_cell = (torch.zeros(1, 1, self.hidden_layer1_size).to(self.device),\n",
    "                             torch.zeros(1, 1, self.hidden_layer1_size).to(self.device))\n",
    "        self.lstm2 = nn.LSTM(input_size=output1_size, hidden_size=hidden_layer2_size)\n",
    "        self.linear2 = nn.Linear(hidden_layer2_size, output_size)\n",
    "        self.hidden2_cell = (torch.zeros(1, 1, self.hidden_layer2_size).to(self.device),\n",
    "                             torch.zeros(1, 1, self.hidden_layer2_size).to(self.device))\n",
    "    \n",
    "    def _minmax(self, x):\n",
    "        x -= x.min(0)[0]\n",
    "        x /= x.max(0)[0]\n",
    "        \n",
    "    def _hardmax(self, x):\n",
    "        x /= x.sum()\n",
    "        \n",
    "    def _sqmax(self, x):\n",
    "        x = x**2\n",
    "        x /= x.sum()\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        #print(len(input_seq), input_seq.shape, input_seq.view(-1, 1, 1).shape)\n",
    "        lstm1_out, self.hidden1_cell = self.lstm1(input_seq.view(-1, 1, self.input_size), self.hidden1_cell)\n",
    "        pred1 = self.linear1(lstm1_out.view(len(input_seq), -1))\n",
    "        lstm2_out, self.hidden2_cell = self.lstm2(pred1.view(-1, 1, self.output1_size), self.hidden2_cell)\n",
    "        predictions = self.linear2(lstm2_out.view(len(pred1), -1))\n",
    "        self._minmax(predictions[-1])\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden1_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer1_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer1_size).to(device)\n",
    "        )     \n",
    "        self.hidden2_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer2_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer2_size).to(device)\n",
    "        )         \n",
    "    \n",
    "class MorseLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the keying model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morse_chr_model = MorseBatchedMultiLSTM(device, hidden_layer1_size=12, output1_size=4, hidden_layer2_size=15, output_size=max_ele+3).to(device) # This is the only way to get things work properly with device\n",
    "morse_chr_model = MorseBatchedLSTM(device, hidden_layer_size=50, output_size=max_ele+3).to(device)\n",
    "morse_chr_loss_function = nn.MSELoss()\n",
    "morse_chr_optimizer = torch.optim.Adam(morse_chr_model.parameters(), lr=0.002)\n",
    "morse_chr_milestones = [4, 9]\n",
    "morse_chr_scheduler = torch.optim.lr_scheduler.MultiStepLR(morse_chr_optimizer, milestones=morse_chr_milestones, gamma=0.5)\n",
    "\n",
    "print(morse_chr_model)\n",
    "print(morse_chr_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_chr_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand(n_prev)\n",
    "X_t = X_t.cuda()\n",
    "print(\"Input shape\", X_t.shape, X_t.view(-1, 1, 1).shape)\n",
    "print(X_t)\n",
    "morse_chr_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(morse_chr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_chr_loader)\n",
    "X, y = next(it)\n",
    "print(X.reshape(n_prev,1).shape, X[0].shape, y[0].shape)\n",
    "print(X[0], y[0])\n",
    "X, y = next(it)\n",
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(morse_chr_scheduler.last_epoch)\n",
    "epochs = 4\n",
    "morse_chr_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_losses = []\n",
    "    loop = tqdm(enumerate(train_chr_loader), total=len(train_chr_loader), leave=True)\n",
    "    for j, train in loop:\n",
    "        X_train = train[0][0]\n",
    "        y_train = train[1][0]\n",
    "        morse_chr_optimizer.zero_grad()\n",
    "        if morse_chr_model.__class__.__name__ in [\"MorseLSTM\", \"MorseLSTM2\", \"MorseBatchedLSTM\", \"MorseBatchedLSTM2\", \"MorseBatchedMultiLSTM\"]:\n",
    "            morse_chr_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_chr_model(X_train)\n",
    "        single_loss = morse_chr_loss_function(y_pred, y_train)\n",
    "        single_loss.backward()\n",
    "        morse_chr_optimizer.step()\n",
    "        train_losses.append(single_loss.item())\n",
    "        # update progress bar\n",
    "        if j % 1000 == 0:\n",
    "            loop.set_description(f\"Epoch [{i+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=np.mean(train_losses))\n",
    "    morse_chr_scheduler.step()\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {np.mean(train_losses):6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model: \n",
    "    torch.save(morse_chr_model.state_dict(), 'models/morse_ord36_model')\n",
    "else:\n",
    "    morse_chr_model.load_state_dict(torch.load('models/morse_ord36_model', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><code>\n",
    "MorseBatchedLSTM(\n",
    "  (lstm): LSTM(1, 50)\n",
    "  (linear): Linear(in_features=50, out_features=8, bias=True)\n",
    ")\n",
    "final:  16 epochs loss: 0.0418\n",
    "CPU times: user 35min 41s, sys: 39.3 s, total: 36min 20s\n",
    "Wall time: 36min 10s\n",
    "126 IFU DE F4EXB = R TNX RPT ES INFO ALEX = RIG IS FTD/1200 GW 10_W ANT IS 3AGI = WX IS SUNNY ES WARM 32C = HW AR F5SFU DE F4EXD K\n",
    "final:   4 epochs loss: 0.0402\n",
    "CPU times: user 8min 57s, sys: 9.29 s, total: 9min 7s\n",
    "Wall time: 9min 4s\n",
    "126 IFU DE F4EXB = R TNX RPT ES INFO ALE4 =RIG IS FTDXJ20_ PWR 100V ANT IS YAGI X WX IS SUNNY ES WARM 32C = HW AR R5SFU DE F4EXB K /// take 1 ///\n",
    "126 IFU BE F4EKD = R TTX RPT ES ITFO ALEV XRIG IS FTDX1200 PWR 100V ANT ES YAGI = WX IS SUNNY EH PARM 32C = HW AR G5SFU DE U4EXB K /// take 2 ///\n",
    "​final:   4 epochs loss: 0.0381 /// in fact it could be good to divide LR again by 2 at 20th epoch ///\n",
    "CPU times: user 8min 55s, sys: 9.62 s, total: 9min 4s\n",
    "Wall time: 9min 2s\n",
    "127 IFU DE F4EXB = R TNX RPT ES INFO ALE4 = RIG IS FTDX1200 PWR 100V ANT IS YAGI X WX IS SUNNY ES WARM 32C = HW AR R5SFU DE F4EXB K\n",
    "127 IFU TE F4EXD X R TTX RWT ES ITUÖ ALEV K NIM SI FTDX1200 PWR 100V ANT ES YAGI = WX IS IUNNY EH PARM 32C = HW AR G5SFU DE U4EXB K\n",
    "final:   4 epochs loss: 0.0351\n",
    "CPU times: user 8min 59s, sys: 9.74 s, total: 9min 9s\n",
    "Wall time: 9min 6s\n",
    "126 IFU DE F4EXB = R TNX RPT ES INFO ALE4 = RIG IS FTDX1200 PWR 100V ANT IS YAGI X WX IS SUNNY E GARM 32C = HW AR F5SFU DE F4EXB K\n",
    "126 SFU NE F4EKB X R TTX RPT ES ITFO TLE4 = NIG SS FTDX1200 PWR 100V ANT ES YAGI X MX ES SUNNY E ÖARM Ü2C = HW AR F5SFU BE A4EXB K\n",
    "final:   4 epochs loss: 0.0355\n",
    "CPU times: user 9min 2s, sys: 10.1 s, total: 9min 12s\n",
    "Wall time: 9min 10s\n",
    "126 IFU DE F4EXB = R TNX RPT ES INFO ALEU = RIG IS FTDX12__ PWR 100V ANT IS YAGI X WX IS SUNNY E GARM V2C = HW AR F5SFU DE F4EXB K\n",
    "126 IRU DE F4EXD X R TTX RPT ES INRO ALEW = GIM SS FTDX1200 PWR 100V ANT AS YAGI = MX IS IUNNY E ÖARM Ü2C = HW AR R5SFU DE U4EXB K\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_char_train = torch.empty(1,max_ele+3).to(device)\n",
    "morse_chr_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(train_chr_loader), total=len(train_chr_loader))\n",
    "for j, train in loop:\n",
    "    with torch.no_grad():\n",
    "        X_chr = train[0][0]\n",
    "        pred_val = morse_chr_model(X_chr)\n",
    "        p_char_train = torch.cat([p_char_train, pred_val.reshape(1,max_ele+3)])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_train = p_char_train[1:] # Remove garbge\n",
    "print(p_char_train.shape) # t -> chars(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post process\n",
    "  \n",
    "  - Move to CPU to ger chars(time)\n",
    "  - Transpose to get times(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_train_c = p_char_train.cpu() # t -> chars(t) on CPU\n",
    "p_char_train_t = torch.transpose(p_char_train_c, 0, 1).cpu() # c -> times(c) on CPU\n",
    "print(p_char_train_c.shape, p_char_train_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chr = train_chr_dataset.X.cpu()\n",
    "label_df_chr = train_chr_dataset.get_labels()\n",
    "env_chr = train_chr_dataset.get_envelope()\n",
    "\n",
    "l_alpha = label_df_chr[n_prev:].reset_index(drop=True)\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(l_alpha[x0:x1][\"chr\"]*3, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev]*0.8, label='sig')\n",
    "plt.plot(env_chr[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(p_char_train_t[0][x0:x1]*0.9 + 1.0, label='e', color=\"orange\")\n",
    "plt.plot(p_char_train_t[1][x0:x1]*0.9 + 1.0, label='c', color=\"green\")\n",
    "plt.plot(p_char_train_t[2][x0:x1]*0.9 + 1.0, label='w', color=\"red\")\n",
    "color_list = [\"green\", \"red\", \"orange\", \"purple\", \"cornflowerblue\"]\n",
    "for i in range(max_ele):\n",
    "    plt.plot(p_char_train_t[i+3][x0:x1]*0.9 + 2.0, label=f'e{i}', color=color_list[i])\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "### Test dataset and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teststr = \"F5SFU DE F4EXB = R TNX RPT ES INFO ALEX = RIG IS FTDX1200 PWR 100W ANT IS YAGI = WX IS SUNNY ES WARM 32C = HW AR F5SFU DE F4EXB KN\"\n",
    "test_cwss = morse_gen.cws_to_cwss(teststr)\n",
    "test_chr_dataset = MorsekeyingDataset(morse_gen, device, -17, 132*5, 27*5, test_cwss, max_ele)\n",
    "test_chr_loader = torch.utils.data.DataLoader(test_chr_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test = torch.empty(1,max_ele+3).to(device)\n",
    "morse_chr_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(test_chr_loader), total=len(test_chr_loader))\n",
    "for j, test in loop:\n",
    "    with torch.no_grad():\n",
    "        X_test = test[0]\n",
    "        pred_val = morse_chr_model(X_test[0])\n",
    "        p_chr_test = torch.cat([p_chr_test, pred_val.reshape(1,max_ele+3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first garbage sample\n",
    "p_chr_test = p_chr_test[1:]\n",
    "print(p_chr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test_c = p_chr_test.cpu() # t -> chars(t) on CPU\n",
    "p_chr_test_t = torch.transpose(p_chr_test_c, 0, 1).cpu() # c -> times(c) on CPU\n",
    "print(p_chr_test_c.shape, p_chr_test_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_chr = test_chr_dataset.X.cpu()\n",
    "label_df_t = test_chr_dataset.get_labels()\n",
    "env_test = test_chr_dataset.get_envelope()\n",
    "l_alpha_t = label_df_t[n_prev:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,4))\n",
    "plt.plot(l_alpha_t[:][\"chr\"]*4, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:]*0.8, label='sig')\n",
    "plt.plot(env_test[n_prev:]*0.9, label='env')\n",
    "plt.plot(p_chr_test_t[0]*0.9 + 1.0, label='e', color=\"purple\")\n",
    "plt.plot(p_chr_test_t[1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_chr_test_t[2]*0.9 + 2.0, label='w', color=\"red\")\n",
    "color_list = [\"green\", \"red\", \"orange\", \"purple\", \"cornflowerblue\"]\n",
    "for i in range(max_ele):\n",
    "    plt_a = plt.plot(p_chr_test_t[i+3]*0.9 + 3.0, label=f'e{i}', color=color_list[i])\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration by moving average\n",
    "\n",
    "Implemented with convolution with a square window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test_tn = p_chr_test_t.numpy()\n",
    "ele_len = round(samples_per_dit / 256)\n",
    "win = np.ones(ele_len)/ele_len\n",
    "p_chr_test_tlp = np.apply_along_axis(lambda m: np.convolve(m, win, mode='full'), axis=1, arr=p_chr_test_tn)\n",
    "\n",
    "plt.figure(figsize=(100,4))\n",
    "plt.plot(l_alpha_t[:][\"chr\"]*4, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:]*0.9, label='sig')\n",
    "plt.plot(env_test[n_prev:]*0.9, label='env')\n",
    "plt.plot(p_chr_test_tlp[0]*0.9 + 1.0, label='e', color=\"purple\")\n",
    "plt.plot(p_chr_test_tlp[1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_chr_test_tlp[2]*0.9 + 2.0, label='w', color=\"red\")\n",
    "color_list = [\"green\", \"red\", \"orange\", \"purple\", \"cornflowerblue\"]\n",
    "for i in range(max_ele):\n",
    "    plt.plot(p_chr_test_tlp[i+3,:]*0.9 + 3.0, label=f'e{i}', color=color_list[i])\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted_lp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test_tn = p_chr_test_t.numpy()\n",
    "ele_len = round(samples_per_dit / 256)\n",
    "win = np.ones(ele_len)/ele_len\n",
    "p_chr_test_tlp = np.apply_along_axis(lambda m: np.convolve(m, win, mode='full'), axis=1, arr=p_chr_test_tn)\n",
    "\n",
    "for i in range(max_ele+3):\n",
    "    p_chr_test_tlp[i][p_chr_test_tlp[i] < 0.5] = 0\n",
    "\n",
    "plt.figure(figsize=(100,4))\n",
    "plt.plot(l_alpha_t[:][\"chr\"]*4, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:]*0.9, label='sig')\n",
    "plt.plot(env_test[n_prev:]*0.9, label='env')\n",
    "plt.plot(p_chr_test_tlp[0]*0.9 + 1.0, label='e', color=\"purple\")\n",
    "plt.plot(p_chr_test_tlp[1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_chr_test_tlp[2]*0.9 + 2.0, label='w', color=\"red\")\n",
    "color_list = [\"green\", \"red\", \"orange\", \"purple\", \"cornflowerblue\"]\n",
    "for i in range(max_ele):\n",
    "    plt.plot(p_chr_test_tlp[i+3,:]*0.9 + 3.0, label=f'e{i}', color=color_list[i])\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted_lpthr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedural decision making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take 1\n",
    "\n",
    "Hard limits with hard values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoderPos:\n",
    "    def __init__(self, alphabet, dit_len, npos, thr):\n",
    "        self.nb_alpha = len(alphabet)\n",
    "        self.alphabet = alphabet\n",
    "        self.dit_len = dit_len\n",
    "        self.npos = npos\n",
    "        self.thr = thr\n",
    "        self.res = \"\"\n",
    "        self.morsestr = \"\"\n",
    "        self.pprev = 0\n",
    "        self.wsep = False\n",
    "        self.csep = False\n",
    "        self.lcounts = [0 for x in range(3+self.npos)]\n",
    "        self.morse_gen = MorseGen.Morse()\n",
    "        self.revmorsecode = self.morse_gen.revmorsecode\n",
    "        self.dit_l = 0.3\n",
    "        self.dit_h = 1.2\n",
    "        self.dah_l = 1.5\n",
    "        print(self.dit_l*dit_len, self.dit_h*dit_len, self.dah_l*dit_len)\n",
    "        \n",
    "    def new_samples(self, samples):\n",
    "        for i, s in enumerate(samples): # e, c, w, [pos]\n",
    "            if s >= self.thr:\n",
    "                self.lcounts[i] += 1\n",
    "            else:\n",
    "                if i == 1:\n",
    "                    self.lcounts[1] = 0\n",
    "                    self.csep = False\n",
    "                if i == 2:\n",
    "                    self.lcounts[2] = 0\n",
    "                    self.wsep = False\n",
    "            if i == 1 and self.lcounts[1] > 1.2*self.dit_len and not self.csep: # character separator\n",
    "                morsestr = \"\"\n",
    "                for ip in range(3,3+self.npos):\n",
    "                    if self.lcounts[ip] >= self.dit_l*self.dit_len and self.lcounts[ip] < self.dit_h*self.dit_len: # dit\n",
    "                        morsestr += \".\"\n",
    "                    elif self.lcounts[ip] > self.dah_l*self.dit_len: # dah\n",
    "                        morsestr += \"-\"\n",
    "                char = self.revmorsecode.get(morsestr, '_') \n",
    "                self.res += char\n",
    "                #print(self.lcounts[3:], morsestr, char)\n",
    "                self.csep = True\n",
    "                self.lcounts[3:] = self.npos*[0]\n",
    "            if i == 2 and self.lcounts[2] > 2.5*self.dit_len and not self.wsep: # word separator\n",
    "                self.res += \" \"\n",
    "                #print(\"w\")\n",
    "                self.wsep = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit_len = round(samples_per_dit / decim)\n",
    "chr_len = round(samples_per_dit*2 / decim)\n",
    "wrd_len = round(samples_per_dit*4 / decim)\n",
    "print(dit_len)\n",
    "decoder = MorseDecoderPos(alphabet, dit_len, max_ele, 0.9)\n",
    "#p_chr_test_clp = torch.transpose(p_chr_test_tlp, 0, 1)\n",
    "p_chr_test_clp = p_chr_test_tlp.transpose()\n",
    "for s in p_chr_test_clp:\n",
    "    decoder.new_samples(s) # e, c, w, [pos]\n",
    "print(len(decoder.res), decoder.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take 2\n",
    "\n",
    "Hard limits with soft values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoderPos:\n",
    "    def __init__(self, alphabet, dit_len, npos, thr):\n",
    "        self.nb_alpha = len(alphabet)\n",
    "        self.alphabet = alphabet\n",
    "        self.dit_len = dit_len\n",
    "        self.npos = npos\n",
    "        self.thr = thr\n",
    "        self.res = \"\"\n",
    "        self.morsestr = \"\"\n",
    "        self.pprev = 0\n",
    "        self.wsep = False\n",
    "        self.csep = False\n",
    "        self.scounts = [0 for x in range(3)] # separators\n",
    "        self.ecounts = [0 for x in range(self.npos)] # Morse elements\n",
    "        self.morse_gen = MorseGen.Morse()\n",
    "        self.revmorsecode = self.morse_gen.revmorsecode\n",
    "        self.dit_l = 0.3\n",
    "        self.dit_h = 1.2\n",
    "        self.dah_l = 1.5\n",
    "        print(self.dit_l*dit_len, self.dit_h*dit_len, self.dah_l*dit_len)\n",
    "        \n",
    "    def new_samples(self, samples):\n",
    "        for i, s in enumerate(samples): # e, c, w, [pos]\n",
    "            if s >= self.thr:\n",
    "                if i < 3:\n",
    "                    self.scounts[i] += 1\n",
    "            else:\n",
    "                if i == 1:\n",
    "                    self.scounts[1] = 0\n",
    "                    self.csep = False\n",
    "                if i == 2:\n",
    "                    self.scounts[2] = 0\n",
    "                    self.wsep = False\n",
    "            if i >= 3:\n",
    "                self.ecounts[i-3] += s\n",
    "            if i == 1 and self.scounts[1] > 1.2*self.dit_len and not self.csep: # character separator\n",
    "                morsestr = \"\"\n",
    "                for ip in range(self.npos):\n",
    "                    if self.ecounts[ip] >= self.dit_l*self.dit_len and self.ecounts[ip] < self.dit_h*self.dit_len: # dit\n",
    "                        morsestr += \".\"\n",
    "                    elif self.ecounts[ip] > self.dah_l*self.dit_len: # dah\n",
    "                        morsestr += \"-\"\n",
    "                char = self.revmorsecode.get(morsestr, '_') \n",
    "                self.res += char\n",
    "                #print(self.ecounts, morsestr, char)\n",
    "                self.csep = True\n",
    "                self.ecounts = self.npos*[0]\n",
    "            if i == 2 and self.scounts[2] > 2.5*self.dit_len and not self.wsep: # word separator\n",
    "                self.res += \" \"\n",
    "                #print(\"w\")\n",
    "                self.wsep = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit_len = round(samples_per_dit / decim)\n",
    "chr_len = round(samples_per_dit*2 / decim)\n",
    "wrd_len = round(samples_per_dit*4 / decim)\n",
    "print(dit_len)\n",
    "decoder = MorseDecoderPos(alphabet, dit_len, max_ele, 0.9)\n",
    "#p_chr_test_clp = torch.transpose(p_chr_test_tlp, 0, 1)\n",
    "p_chr_test_clp = p_chr_test_tlp.transpose()\n",
    "for s in p_chr_test_clp:\n",
    "    decoder.new_samples(s) # e, c, w, [pos]\n",
    "print(len(decoder.res), decoder.res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
