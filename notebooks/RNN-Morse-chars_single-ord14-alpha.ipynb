{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with dit dah sequence recognition - 14 characters - element order prediction\n",
    "\n",
    "Builds on `RNN-Morse-chars-single-ddp06` with element order encoding, In `RNN-Morse-chars-single-ddp06` particularly when applyijng minmax on the raw predictions we noticed that it was not good at all at sorting the dits and dahs (everything went to the dah senses) but was good at predicting the element (dit or dah) relative position (order). Here we exploit this feature exclusively. The length of dits and dahs is roughly respected and the element (the \"on\" keying) is reinforced from the noisy original signal.\n",
    "\n",
    "Uses 3 element Morse encoding thus the 14 character alphabet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create string\n",
    "\n",
    "Each character in the alphabet should happen a large enough number of times. As a rule of thumb we will take some multiple of the number of characters in the alphabet. If the multiplier is large enough the probability of each character appearance will be even over the alphabet. \n",
    "\n",
    "Seems to get better results looking at the gated graphs but procedural decision has to be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "\n",
    "morse_gen = MorseGen.Morse()\n",
    "alphabet = morse_gen.alphabet14\n",
    "print(132/len(alphabet))\n",
    "\n",
    "morsestr = MorseGen.get_morse_str(nchars=132*7, nwords=27*7, chars=alphabet)\n",
    "print(alphabet)\n",
    "print(len(morsestr), morsestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframe and extract envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 8000\n",
    "decim = 128\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/decim)*12*2) + 1\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/decim:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim_str(morsestr, samples_per_dit, decim, alphabet)\n",
    "env = label_df['env'].to_numpy()\n",
    "print(type(env), len(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_new_data(morse_gen, decim, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "    if not phrase:\n",
    "        phrase = MorseGen.get_morse_str(nchars=nchars, nwords=nwords, chars=alphabet)\n",
    "    print(len(phrase), phrase)\n",
    "    Fs = 8000\n",
    "    samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "    n_prev = int((samples_per_dit/decim)*19) + 1 # number of samples to look back is slightly more than a \"O\" a word space (3*4+7=19)\n",
    "    #n_prev = int((samples_per_dit/decim)*27) + 1 # number of samples to look back is slightly more than a \"0\" a word space (5*4+7=27)\n",
    "    print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/decim:.2f}. Look back is {n_prev}.')\n",
    "    label_df = morse_gen.encode_df_decim_ord(phrase, samples_per_dit, decim, alphabet)\n",
    "    # extract the envelope\n",
    "    envelope = label_df['env'].to_numpy()\n",
    "    # remove the envelope\n",
    "    label_df.drop(columns=['env'], inplace=True)\n",
    "    SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "    SNR_linear *= 256 # Apply original FFT\n",
    "    print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "    t = np.linspace(0, len(envelope)-1, len(envelope))\n",
    "    power = np.sum(envelope**2)/len(envelope)\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(envelope))\n",
    "    # noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "    signal = (envelope + noise)**2\n",
    "    signal[signal > 1.0] = 1.0 # a bit crap ...\n",
    "    return envelope, signal, label_df, n_prev, morse_gen.max_ele(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "envelope, signal, label_df, n_prev, max_ele = get_new_data(morse_gen, decim, SNR_dB=-17, phrase=morsestr, alphabet=alphabet)\n",
    "\n",
    "# Show\n",
    "print(n_prev)\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "    \n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,4))\n",
    "plt.plot(signal[x0:x1]*0.7, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 1.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 1.0, label='chr', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 1.0, label='wrd')\n",
    "for i in range(max_ele):\n",
    "    plt.plot(label_df[x0:x1][f'e{i}']*0.9 + 2.0 + i, label=f'e{i}')\n",
    "plt.title(\"signal and labels\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader\n",
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MorsekeyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, morse_gen, decim, device, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "        self.envelope, self.signal, self.label_df0, self.seq_len, self.max_ele = get_new_data(morse_gen, decim, SNR_dB=SNR_dB, phrase=phrase, alphabet=alphabet)\n",
    "        self.label_df = self.label_df0\n",
    "        self.X = torch.FloatTensor(self.signal).to(device)\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_envelope(self):\n",
    "        return self.envelope\n",
    "    \n",
    "    def get_signal(self):\n",
    "        return self.signal\n",
    "    \n",
    "    def get_X(self):\n",
    "        return self.X\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_labels0(self):\n",
    "        return self.label_df0\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len()\n",
    "    \n",
    "    def max_ele(self):\n",
    "        return self.max_ele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keying data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_chr_dataset = MorsekeyingDataset(morse_gen, decim, device, -20, 132*5, 27*5, morsestr, alphabet)\n",
    "train_chr_loader = torch.utils.data.DataLoader(train_chr_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = train_chr_dataset.get_signal()\n",
    "envelope = train_chr_dataset.get_envelope()\n",
    "label_df = train_chr_dataset.get_labels()\n",
    "label_df0 = train_chr_dataset.get_labels0()\n",
    "\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 2000\n",
    "\n",
    "plt.figure(figsize=(50,4))\n",
    "plt.plot(signal[x0:x1]*0.8, label=\"sig\", color=\"cornflowerblue\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 1.0, label='ele', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 1.0, label='chr', color=\"green\")\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 1.0, label='wrd', color=\"red\")\n",
    "for i in range(max_ele):\n",
    "    label_key = f'e{i}'\n",
    "    plt.plot(label_df[x0:x1][label_key]*0.9 + 2.0, label=label_key)\n",
    "plt.title(\"keying - signal and labels\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseBatchedLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "    \n",
    "    def _minmax(self, x):\n",
    "        x -= x.min(0)[0]\n",
    "        x /= x.max(0)[0]\n",
    "        \n",
    "    def _hardmax(self, x):\n",
    "        x /= x.sum()\n",
    "        \n",
    "    def _sqmax(self, x):\n",
    "        x = x**2\n",
    "        x /= x.sum()\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        #print(len(input_seq), input_seq.shape, input_seq.view(-1, 1, 1).shape)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(-1, 1, self.input_size), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        self._minmax(predictions[-1])\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )     \n",
    "    \n",
    "class MorseLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the keying model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_chr_model = MorseBatchedLSTM(device, hidden_layer_size=12, output_size=max_ele+3).to(device) # This is the only way to get things work properly with device\n",
    "morse_chr_loss_function = nn.MSELoss()\n",
    "morse_chr_optimizer = torch.optim.Adam(morse_chr_model.parameters(), lr=0.002)\n",
    "morse_chr_milestones = [2, 6]\n",
    "morse_chr_scheduler = torch.optim.lr_scheduler.MultiStepLR(morse_chr_optimizer, milestones=morse_chr_milestones, gamma=0.5)\n",
    "\n",
    "print(morse_chr_model)\n",
    "print(morse_chr_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_chr_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand(n_prev)\n",
    "X_t = X_t.cuda()\n",
    "print(\"Input shape\", X_t.shape, X_t.view(-1, 1, 1).shape)\n",
    "print(X_t)\n",
    "morse_chr_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(morse_chr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_chr_loader)\n",
    "X, y = next(it)\n",
    "print(X.reshape(n_prev,1).shape, X[0].shape, y[0].shape)\n",
    "print(X[0], y[0])\n",
    "X, y = next(it)\n",
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(morse_chr_scheduler.last_epoch)\n",
    "epochs = 10\n",
    "morse_chr_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_losses = []\n",
    "    loop = tqdm(enumerate(train_chr_loader), total=len(train_chr_loader), leave=True)\n",
    "    for j, train in loop:\n",
    "        X_train = train[0][0]\n",
    "        y_train = train[1][0]\n",
    "        morse_chr_optimizer.zero_grad()\n",
    "        if morse_chr_model.__class__.__name__ in [\"MorseLSTM\", \"MorseLSTM2\", \"MorseBatchedLSTM\", \"MorseBatchedLSTM2\"]:\n",
    "            morse_chr_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_chr_model(X_train)\n",
    "        single_loss = morse_chr_loss_function(y_pred, y_train)\n",
    "        single_loss.backward()\n",
    "        morse_chr_optimizer.step()\n",
    "        train_losses.append(single_loss.item())\n",
    "        # update progress bar\n",
    "        if j % 1000 == 0:\n",
    "            loop.set_description(f\"Epoch [{i+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=np.mean(train_losses))\n",
    "    morse_chr_scheduler.step()\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {np.mean(train_losses):6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_chr_scheduler.last_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model: \n",
    "    torch.save(morse_chr_model.state_dict(), 'models/morse_ord14_model')\n",
    "else:\n",
    "    morse_chr_model.load_state_dict(torch.load('models/morse_ord14_model', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_char_train = torch.empty(1,max_ele+3).to(device)\n",
    "morse_chr_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(train_chr_loader), total=len(train_chr_loader))\n",
    "for j, train in loop:\n",
    "    with torch.no_grad():\n",
    "        X_chr = train[0][0]\n",
    "        pred_val = morse_chr_model(X_chr)\n",
    "        p_char_train = torch.cat([p_char_train, pred_val.reshape(1,max_ele+3)])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_train = p_char_train[1:] # Remove garbge\n",
    "print(p_char_train.shape) # t -> chars(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post process\n",
    "  \n",
    "  - Move to CPU to ger chars(time)\n",
    "  - Transpose to get times(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_train_c = p_char_train.cpu() # t -> chars(t) on CPU\n",
    "p_char_train_t = torch.transpose(p_char_train_c, 0, 1).cpu() # c -> times(c) on CPU\n",
    "print(p_char_train_c.shape, p_char_train_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chr = train_chr_dataset.X.cpu()\n",
    "label_df_chr = train_chr_dataset.get_labels()\n",
    "env_chr = train_chr_dataset.get_envelope()\n",
    "\n",
    "l_alpha = label_df_chr[n_prev:].reset_index(drop=True)\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(l_alpha[x0:x1][\"chr\"]*3, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev]*0.8, label='sig')\n",
    "plt.plot(env_chr[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(p_char_train_t[0][x0:x1]*0.9 + 1.0, label='e', color=\"orange\")\n",
    "plt.plot(p_char_train_t[1][x0:x1]*0.9 + 1.0, label='c', color=\"green\")\n",
    "plt.plot(p_char_train_t[2][x0:x1]*0.9 + 1.0, label='w', color=\"red\")\n",
    "for i in range(max_ele):\n",
    "    plt.plot(p_char_train_t[i+3][x0:x1]*0.9 + 2.0, label=f'e{i}')\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "### Test dataset and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teststr = \"AA MON SINGE SONGE ET MON MANTEAU KAKI EST TOUT KAKA AA\"\n",
    "#decim=80\n",
    "test_chr_dataset = MorsekeyingDataset(morse_gen, decim, device, -17, 132*5, 27*5, teststr, alphabet)\n",
    "test_chr_loader = torch.utils.data.DataLoader(test_chr_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test = torch.empty(1,max_ele+3).to(device)\n",
    "morse_chr_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(test_chr_loader), total=len(test_chr_loader))\n",
    "for j, test in loop:\n",
    "    with torch.no_grad():\n",
    "        X_test = test[0]\n",
    "        pred_val = morse_chr_model(X_test[0])\n",
    "        p_chr_test = torch.cat([p_chr_test, pred_val.reshape(1,max_ele+3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first garbage sample\n",
    "p_chr_test = p_chr_test[1:]\n",
    "print(p_chr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test_c = p_chr_test.cpu() # t -> chars(t) on CPU\n",
    "p_chr_test_t = torch.transpose(p_chr_test_c, 0, 1).cpu() # c -> times(c) on CPU\n",
    "print(p_chr_test_c.shape, p_chr_test_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_chr = test_chr_dataset.X.cpu()\n",
    "label_df_t = test_chr_dataset.get_labels()\n",
    "env_test = test_chr_dataset.get_envelope()\n",
    "l_alpha_t = label_df_t[n_prev:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,4))\n",
    "plt.plot(l_alpha_t[:][\"chr\"]*4, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:]*0.8, label='sig')\n",
    "plt.plot(env_test[n_prev:]*0.9, label='env')\n",
    "plt.plot(p_chr_test_t[0]*0.9 + 1.0, label='e', color=\"purple\")\n",
    "plt.plot(p_chr_test_t[1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_chr_test_t[2]*0.9 + 2.0, label='w', color=\"red\")\n",
    "colors = [\"green\", \"red\", \"orange\", \"purple\", \"cornflowerblue\"]\n",
    "for i in range(max_ele):\n",
    "    plt_a = plt.plot(p_chr_test_t[i+3]*0.9 + 3.0, label=f'e{i}', color=colors[i])\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration by moving average\n",
    "\n",
    "Implemented with convolution with a square window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test_tn = p_chr_test_t.numpy()\n",
    "ele_len = round(samples_per_dit / 256)\n",
    "win = np.ones(ele_len)/ele_len\n",
    "p_chr_test_tlp = np.apply_along_axis(lambda m: np.convolve(m, win, mode='full'), axis=1, arr=p_chr_test_tn)\n",
    "\n",
    "plt.figure(figsize=(100,4))\n",
    "plt.plot(l_alpha_t[:][\"chr\"]*4, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:]*0.9, label='sig')\n",
    "plt.plot(env_test[n_prev:]*0.9, label='env')\n",
    "plt.plot(p_chr_test_tlp[0]*0.9 + 1.0, label='e', color=\"purple\")\n",
    "plt.plot(p_chr_test_tlp[1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_chr_test_tlp[2]*0.9 + 2.0, label='w', color=\"red\")\n",
    "colors = [\"green\", \"red\", \"orange\", \"purple\", \"cornflowerblue\"]\n",
    "for i in range(max_ele):\n",
    "    plt.plot(p_chr_test_tlp[i+3,:]*0.9 + 3.0, label=f'e{i}', color=colors[i])\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test_tn = p_chr_test_t.numpy()\n",
    "ele_len = round(samples_per_dit / 256)\n",
    "win = np.ones(ele_len)/ele_len\n",
    "p_chr_test_tlp = np.apply_along_axis(lambda m: np.convolve(m, win, mode='full'), axis=1, arr=p_chr_test_tn)\n",
    "\n",
    "for i in range(max_ele+3):\n",
    "    p_chr_test_tlp[i][p_chr_test_tlp[i] < 0.9] = 0\n",
    "\n",
    "plt.figure(figsize=(100,4))\n",
    "plt.plot(l_alpha_t[:][\"chr\"]*4, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:]*0.9, label='sig')\n",
    "plt.plot(env_test[n_prev:]*0.9, label='env')\n",
    "plt.plot(p_chr_test_tlp[0]*0.9 + 1.0, label='e', color=\"purple\")\n",
    "plt.plot(p_chr_test_tlp[1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_chr_test_tlp[2]*0.9 + 2.0, label='w', color=\"red\")\n",
    "color_list = [\"green\", \"red\", \"orange\", \"purple\", \"cornflowerblue\"]\n",
    "for i in range(max_ele):\n",
    "    plt.plot(p_chr_test_tlp[i+3,:]*0.9 + 3.0, label=f'e{i}', color=color_list[i])\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted_lpthr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedural decision making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take 1\n",
    "\n",
    "Hard limits with hard values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoderPos:\n",
    "    def __init__(self, alphabet, dit_len, npos, thr):\n",
    "        self.nb_alpha = len(alphabet)\n",
    "        self.alphabet = alphabet\n",
    "        self.dit_len = dit_len\n",
    "        self.npos = npos\n",
    "        self.thr = thr\n",
    "        self.res = \"\"\n",
    "        self.morsestr = \"\"\n",
    "        self.pprev = 0\n",
    "        self.wsep = False\n",
    "        self.csep = False\n",
    "        self.lcounts = [0 for x in range(3+self.npos)]\n",
    "        self.morse_gen = MorseGen.Morse()\n",
    "        self.revmorsecode = self.morse_gen.revmorsecode\n",
    "        self.dit_l = 0.3\n",
    "        self.dit_h = 1.2\n",
    "        self.dah_l = 1.5\n",
    "        print(self.dit_l*dit_len, self.dit_h*dit_len, self.dah_l*dit_len)\n",
    "        \n",
    "    def new_samples(self, samples):\n",
    "        for i, s in enumerate(samples): # e, c, w, [pos]\n",
    "            if s >= self.thr:\n",
    "                self.lcounts[i] += 1\n",
    "            else:\n",
    "                if i == 1:\n",
    "                    self.lcounts[1] = 0\n",
    "                    self.csep = False\n",
    "                if i == 2:\n",
    "                    self.lcounts[2] = 0\n",
    "                    self.wsep = False\n",
    "            if i == 1 and self.lcounts[1] > 1.2*self.dit_len and not self.csep: # character separator\n",
    "                morsestr = \"\"\n",
    "                for ip in range(3,3+self.npos):\n",
    "                    if self.lcounts[ip] >= self.dit_l*self.dit_len and self.lcounts[ip] < self.dit_h*self.dit_len: # dit\n",
    "                        morsestr += \".\"\n",
    "                    elif self.lcounts[ip] > self.dah_l*self.dit_len: # dah\n",
    "                        morsestr += \"-\"\n",
    "                char = self.revmorsecode.get(morsestr, '_') \n",
    "                self.res += char\n",
    "                #print(self.lcounts[3:], morsestr, char)\n",
    "                self.csep = True\n",
    "                self.lcounts[3:] = self.npos*[0]\n",
    "            if i == 2 and self.lcounts[2] > 2.5*self.dit_len and not self.wsep: # word separator\n",
    "                self.res += \" \"\n",
    "                #print(\"w\")\n",
    "                self.wsep = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit_len = round(samples_per_dit / decim)\n",
    "chr_len = round(samples_per_dit*2 / decim)\n",
    "wrd_len = round(samples_per_dit*4 / decim)\n",
    "print(dit_len)\n",
    "decoder = MorseDecoderPos(alphabet, dit_len, 3, 0.9)\n",
    "#p_chr_test_clp = torch.transpose(p_chr_test_tlp, 0, 1)\n",
    "p_chr_test_clp = p_chr_test_tlp.transpose()\n",
    "for s in p_chr_test_clp:\n",
    "    decoder.new_samples(s) # e, c, w, [pos]\n",
    "print(len(decoder.res), decoder.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take 2\n",
    "\n",
    "Hard limits with soft values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoderPos:\n",
    "    def __init__(self, alphabet, dit_len, npos, thr):\n",
    "        self.nb_alpha = len(alphabet)\n",
    "        self.alphabet = alphabet\n",
    "        self.dit_len = dit_len\n",
    "        self.npos = npos\n",
    "        self.thr = thr\n",
    "        self.res = \"\"\n",
    "        self.morsestr = \"\"\n",
    "        self.pprev = 0\n",
    "        self.wsep = False\n",
    "        self.csep = False\n",
    "        self.scounts = [0 for x in range(3)] # separators\n",
    "        self.ecounts = [0 for x in range(self.npos)] # Morse elements\n",
    "        self.morse_gen = MorseGen.Morse()\n",
    "        self.revmorsecode = self.morse_gen.revmorsecode\n",
    "        self.dit_l = 0.3\n",
    "        self.dit_h = 1.2\n",
    "        self.dah_l = 1.5\n",
    "        print(self.dit_l*dit_len, self.dit_h*dit_len, self.dah_l*dit_len)\n",
    "        \n",
    "    def new_samples(self, samples):\n",
    "        for i, s in enumerate(samples): # e, c, w, [pos]\n",
    "            if s >= self.thr:\n",
    "                if i < 3:\n",
    "                    self.scounts[i] += 1\n",
    "            else:\n",
    "                if i == 1:\n",
    "                    self.scounts[1] = 0\n",
    "                    self.csep = False\n",
    "                if i == 2:\n",
    "                    self.scounts[2] = 0\n",
    "                    self.wsep = False\n",
    "            if i >= 3:\n",
    "                self.ecounts[i-3] += s\n",
    "            if i == 1 and self.scounts[1] > 1.2*self.dit_len and not self.csep: # character separator\n",
    "                morsestr = \"\"\n",
    "                for ip in range(self.npos):\n",
    "                    if self.ecounts[ip] >= self.dit_l*self.dit_len and self.ecounts[ip] < self.dit_h*self.dit_len: # dit\n",
    "                        morsestr += \".\"\n",
    "                    elif self.ecounts[ip] > self.dah_l*self.dit_len: # dah\n",
    "                        morsestr += \"-\"\n",
    "                char = self.revmorsecode.get(morsestr, '_') \n",
    "                self.res += char\n",
    "                #print(self.ecounts, morsestr, char)\n",
    "                self.csep = True\n",
    "                self.ecounts = self.npos*[0]\n",
    "            if i == 2 and self.scounts[2] > 2.5*self.dit_len and not self.wsep: # word separator\n",
    "                self.res += \" \"\n",
    "                #print(\"w\")\n",
    "                self.wsep = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit_len = round(samples_per_dit / decim)\n",
    "chr_len = round(samples_per_dit*2 / decim)\n",
    "wrd_len = round(samples_per_dit*4 / decim)\n",
    "print(dit_len)\n",
    "decoder = MorseDecoderPos(alphabet, dit_len, 3, 0.9)\n",
    "#p_chr_test_clp = torch.transpose(p_chr_test_tlp, 0, 1)\n",
    "p_chr_test_clp = p_chr_test_tlp.transpose()\n",
    "for s in p_chr_test_clp:\n",
    "    decoder.new_samples(s) # e, c, w, [pos]\n",
    "print(len(decoder.res), decoder.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoderPos:\n",
    "    def __init__(self, alphabet, dit_len, npos, thr):\n",
    "        self.nb_alpha = len(alphabet)\n",
    "        self.alphabet = alphabet\n",
    "        self.dit_len = dit_len\n",
    "        self.npos = npos\n",
    "        self.thr = thr\n",
    "        self.res = \"\"\n",
    "        self.morsestr = \"\"\n",
    "        self.pprev = 0\n",
    "        self.wsep = False\n",
    "        self.lcounts = [0 for x in range(3+self.npos)]\n",
    "        self.morse_gen = MorseGen.Morse()\n",
    "        self.revmorsecode = self.morse_gen.revmorsecode\n",
    "        self.dit_l = 0.3\n",
    "        self.dit_h = 1.2\n",
    "        self.dah_l = 1.5\n",
    "        print(self.dit_l*dit_len, self.dit_h*dit_len, self.dah_l*dit_len)        \n",
    "        \n",
    "    def new_samples(self, samples):\n",
    "        for i, s in enumerate(samples): # e, c, w, [pos]\n",
    "            if s >= self.thr:\n",
    "                self.lcounts[i] += 1\n",
    "                if i > 2: # character\n",
    "                    p = i - 3\n",
    "                    if p < self.pprev:\n",
    "                        morsestr = \"\"\n",
    "                        for ip in range(3,4+self.pprev):\n",
    "                            if self.lcounts[ip] >= self.dit_l*self.dit_len and self.lcounts[ip] < self.dit_h*self.dit_len: # dit\n",
    "                                morsestr += \".\"\n",
    "                            elif self.lcounts[ip] > self.dah_l*self.dit_len: # dah\n",
    "                                morsestr += \"-\"\n",
    "                        char = self.revmorsecode.get(morsestr, '_')\n",
    "                        self.res += char\n",
    "                        #print(self.pprev, self.lcounts[2:], morsestr, char)\n",
    "                        self.lcounts[3:] = self.npos*[0]\n",
    "                    self.pprev = p \n",
    "                elif i == 1: # char delimiter\n",
    "                    if self.lcounts[2] > 2.5*self.dit_len:\n",
    "                        self.res += \" \"\n",
    "                        self.lcounts[2] = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
