{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with character recognition - hybrid solution\n",
    "\n",
    "Builds on `RNN-Morse-chars-key`. It appears that only the keying recognition model works more or less. With the post-processing done in `RNN-Morse-chars-key` that essentially consist in windowing by the element separator sense signal and set the dahs sense signal by subtracting of the original dits sense signal (some scaling of the dits sense signal also) we obtain fairly good stimuli that can feed a classical logic based on the positive edge trigger of dits, dahs and character separator signals.  \n",
    "\n",
    "Here we re-introduce the alphanumeric alphabet (36 characters) as we are not bound by the character model.\n",
    "\n",
    "It sort of works (the only option giving some results so far) but is impaired by hard decisions. Still missing a second good model for character recognition with DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create string\n",
    "\n",
    "Each character in the alphabet should happen a large enough number of times. As a rule of thumb we will take some multiple of the number of characters in the alphabet. If the multiplier is large enough the probability of each character appearance will be even over the alphabet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "\n",
    "morse_gen = MorseGen.Morse()\n",
    "alphabet = morse_gen.alphabet36\n",
    "print(132/len(alphabet))\n",
    "\n",
    "morsestr = MorseGen.get_morse_str(nchars=132*2, nwords=27*2, chars=alphabet)\n",
    "print(alphabet)\n",
    "print(len(morsestr), morsestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframe and extract envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 8000\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*19) + 1\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim_str(morsestr, samples_per_dit, 128, alphabet)\n",
    "env = label_df['env'].to_numpy()\n",
    "print(type(env), len(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_new_data(morse_gen, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "    if not phrase:\n",
    "        phrase = MorseGen.get_morse_str(nchars=nchars, nwords=nwords, chars=alphabet)\n",
    "    print(len(phrase), phrase)\n",
    "    Fs = 8000\n",
    "    samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "    n_prev = int((samples_per_dit/128)*19) + 1 # number of samples to look back is slightly more than a dit-dah and a word space (2+3+7=12)\n",
    "    print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "    label_df = morse_gen.encode_df_decim_str(phrase, samples_per_dit, 128, alphabet)\n",
    "    # extract the envelope\n",
    "    envelope = label_df['env'].to_numpy()\n",
    "    # remove the envelope\n",
    "    label_df.drop(columns=['env'], inplace=True)\n",
    "    SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "    SNR_linear *= 256 # Apply original FFT\n",
    "    print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "    t = np.linspace(0, len(envelope)-1, len(envelope))\n",
    "    power = np.sum(envelope**2)/len(envelope)\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(envelope))\n",
    "    # noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "    signal = (envelope + noise)**2\n",
    "    signal[signal > 1.0] = 1.0 # a bit crap ...\n",
    "    return envelope, signal, label_df, n_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "envelope, signal, label_df, n_prev = get_new_data(morse_gen, SNR_dB=-17, phrase=morsestr, alphabet=alphabet)\n",
    "\n",
    "# Show\n",
    "print(n_prev)\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "print(max(signal))\n",
    "    \n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0:x1]*0.9, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 1.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 2.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 2.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"signal and keying labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,1.0+0.5*len(morse_gen.alphabet)))\n",
    "plt.plot(signal[x0:x1]*0.9, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "for i, a in enumerate(alphabet):\n",
    "    plt.plot(label_df[x0:x1][a]*0.9 + 1.0 + i, label=a)\n",
    "plt.title(\"alpha labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader for keying model\n",
    "### Define keying dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MorsekeyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, morse_gen, device, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "        self.envelope, self.signal, self.label_df0, self.seq_len = get_new_data(morse_gen, SNR_dB=SNR_dB, phrase=phrase, alphabet=alphabet)\n",
    "        self.label_df = self.label_df0[['dit','dah','ele','chr','wrd']]\n",
    "        self.X = torch.FloatTensor(self.signal).to(device)\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_envelope(self):\n",
    "        return self.envelope\n",
    "    \n",
    "    def get_signal(self):\n",
    "        return self.signal\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_labels0(self):\n",
    "        return self.label_df0\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keying data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_keying_dataset = MorsekeyingDataset(morse_gen, device, -20, 132*5, 27*5, morsestr, alphabet)\n",
    "train_keying_loader = torch.utils.data.DataLoader(train_keying_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = train_keying_dataset.get_signal()\n",
    "signal = (signal - min(signal))\n",
    "label_df = train_keying_dataset.get_labels()\n",
    "label_df0 = train_keying_dataset.get_labels0()\n",
    "\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0:x1]*0.9, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 1.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 2.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 2.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"keying - signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model classes\n",
    "\n",
    "The model classes are the same they will be instantiated differently for keying and character models \n",
    "\n",
    "### Create model for keying recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseBatchedLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "        self.m = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        #print(len(input_seq), input_seq.shape, input_seq.view(-1, 1, 1).shape)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(-1, 1, self.input_size), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return self.m(predictions[-1])\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )     \n",
    "    \n",
    "class MorseLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the keying model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_key_model = MorseBatchedLSTM(device, hidden_layer_size=12, output_size=5).to(device) # This is the only way to get things work properly with device\n",
    "morse_key_loss_function = nn.MSELoss()\n",
    "morse_key_optimizer = torch.optim.Adam(morse_key_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_key_model)\n",
    "print(morse_key_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_key_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand(n_prev)\n",
    "#X_t = torch.tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385])\n",
    "X_t = X_t.cuda()\n",
    "print(\"Input shape\", X_t.shape, X_t.view(-1, 1, 1).shape)\n",
    "print(X_t)\n",
    "morse_key_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "channels=10\n",
    "H=n_prev\n",
    "W=1\n",
    "torchinfo.summary(morse_key_model, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train keying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_keying_loader)\n",
    "X, y = next(it)\n",
    "print(X.reshape(n_prev,1).shape, X[0].shape, y[0].shape)\n",
    "print(X[0], y[0])\n",
    "X, y = next(it)\n",
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epochs = 20\n",
    "morse_key_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_losses = []\n",
    "    loop = tqdm(enumerate(train_keying_loader), total=len(train_keying_loader), leave=True)\n",
    "    for j, train in loop:\n",
    "        X_train = train[0][0]\n",
    "        y_train = train[1][0]\n",
    "        morse_key_optimizer.zero_grad()\n",
    "        if morse_key_model.__class__.__name__ in [\"MorseLSTM\", \"MorseLSTM2\", \"MorseBatchedLSTM\", \"MorseBatchedLSTM2\"]:\n",
    "            morse_key_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_key_model(X_train)\n",
    "        single_loss = morse_key_loss_function(y_pred, y_train)\n",
    "        single_loss.backward()\n",
    "        morse_key_optimizer.step()\n",
    "        train_losses.append(single_loss.item())\n",
    "        # update progress bar\n",
    "        if j % 1000 == 0:\n",
    "            loop.set_description(f\"Epoch [{i+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=np.mean(train_losses))\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {np.mean(train_losses):6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model: \n",
    "    torch.save(morse_key_model.state_dict(), 'models/morse_key_model')\n",
    "else:\n",
    "    morse_key_model.load_state_dict(torch.load('models/morse_key_model', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results for next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_key_train = torch.empty(1,5).to(device)\n",
    "morse_key_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(train_keying_loader), total=len(train_keying_loader))\n",
    "for j, train in loop:\n",
    "    with torch.no_grad():\n",
    "        X_train = train[0]\n",
    "        pred_val = morse_key_model(X_train[0])\n",
    "        p_key_train = torch.cat([p_key_train, pred_val.reshape(1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first garbage sample\n",
    "p_key_train = p_key_train[1:]\n",
    "print(p_key_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_key_train[0:2])\n",
    "p_dits = p_key_train[:,0].to('cpu').numpy()\n",
    "p_dahs = p_key_train[:,1].to('cpu').numpy()\n",
    "p_eles = p_key_train[:,2].to('cpu').numpy()\n",
    "p_chrs = p_key_train[:,3].to('cpu').numpy()\n",
    "p_wrds = p_key_train[:,4].to('cpu').numpy()\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0+n_prev:x1+n_prev]*0.9, label=\"sig\")\n",
    "plt.plot(envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(p_dits[x0:x1]*0.9 + 1.0, label='dit')\n",
    "plt.plot(p_dahs[x0:x1]*0.9 + 1.0, label='dah')\n",
    "plt.plot(p_eles[x0:x1]*0.9 + 2.0, label='ele')\n",
    "plt.plot(p_chrs[x0:x1]*0.9 + 2.0, label='chr')\n",
    "plt.plot(p_wrds[x0:x1]*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"keying - predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit_shift = round(samples_per_dit / 128)\n",
    "dit2_shift = round(samples_per_dit / 64)\n",
    "dit3_shift = round(samples_per_dit / 32)\n",
    "print(dit_shift, dit2_shift, dit3_shift)\n",
    "dah2_shift = dit2_shift - dit_shift\n",
    "dah3_shift = dit3_shift - dit2_shift\n",
    "print(dah2_shift, dah3_shift)\n",
    "\n",
    "elem_window = p_eles[dit_shift:]\n",
    "w_dits = p_dits[:-dit_shift] * elem_window\n",
    "w_dahs = p_dahs[:-dit_shift] * elem_window\n",
    "w_dahs -= w_dits\n",
    "w_dahs2 = w_dahs[dah2_shift:]\n",
    "w_dahs3 = w_dahs[dah3_shift:]\n",
    "w_chrs = p_chrs[dit_shift:]\n",
    "w_wrds = p_wrds[dit_shift:]\n",
    "\n",
    "w_dits *= 2.0\n",
    "w_dits[w_dits > 1.0] = 1.0\n",
    "\n",
    "label_char_df = train_keying_dataset.get_labels0().drop(columns=['dit','dah','ele','chr','wrd'])\n",
    "label_char_df = label_char_df[n_prev:].reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0+n_prev:x1+n_prev]*0.9, label=\"sig\")\n",
    "plt.plot(envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(w_dits[x0:x1]*0.9 + 1.0, label='dit')\n",
    "plt.plot(w_dahs[x0:x1]*0.9 + 1.0, label='dah')\n",
    "plt.plot(w_dahs2[x0:x1]*0.9 + 1.0, label='da2', alpha=0.5)\n",
    "plt.plot(w_dahs3[x0:x1]*0.9 + 1.0, label='da3', alpha=0.5)\n",
    "#plt.plot(p_eles[x0+dit_shift:x1+dit_shift]*0.9 + 2.0, label='ele')\n",
    "plt.plot(w_chrs[x0:x1]*0.9 + 2.0, label='chr')\n",
    "plt.plot(w_wrds[x0:x1]*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"keying - predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi frequency reconstruction\n",
    "\n",
    "The idea is to use the resulting dits and dahs sense signals in their original shape. The lengths of dits and dahs are therefore similar. To help distinguish between them by ear one would assign a higher pitch to the dits (thus mimicking the \"i\" of the dit) and a lower pitch to the dahs (thus mimicking the \"ah\" of the dah). Moreover to reconstruct the rhythm the dahs sense is delayed by two dits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.special\n",
    "from scipy.io import wavfile\n",
    "\n",
    "Fdah = 440 # A4\n",
    "Fdit = 523 # C5\n",
    "Fs = 8000\n",
    "noverlap = 128\n",
    "decim = 128\n",
    "\n",
    "dit_mod = w_dits[:-dah3_shift]\n",
    "dit_wav = np.array([[x]*noverlap for x in dit_mod]).flatten()\n",
    "dah_mod = w_dahs3\n",
    "dah_wav = np.array([[x]*noverlap for x in dah_mod]).flatten()\n",
    "\n",
    "dit_wt = (Fdit / Fs)*2*np.pi\n",
    "dah_wt = (Fdah / Fs)*2*np.pi\n",
    "dit_tone = np.sin(np.arange(len(dit_wav))*dit_wt)\n",
    "dah_tone = np.sin(np.arange(len(dah_wav))*dah_wt)\n",
    "\n",
    "wavfile.write('audio/bif.wav', Fs, dit_tone*dit_wav + dah_tone*dah_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mono frequency reconstruction\n",
    "\n",
    "Here we stick to more convenient Morse code. In order to do so 2 delayed copies of the dahs sense signal are summed to reconstruct the length of an original dah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fcode = 523\n",
    "\n",
    "mod_len = min(len(w_dits), len(w_dahs), len(w_dahs2), len(w_dahs3))\n",
    "dit_mod = w_dits[:mod_len]\n",
    "dah_mod = w_dahs[:mod_len] + w_dahs2[:mod_len] + w_dahs3[:mod_len]\n",
    "all_mod = dit_mod + dah_mod\n",
    "mod_wav = np.array([[x]*noverlap for x in all_mod]).flatten()\n",
    "\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(dit_wav))*wt)\n",
    "\n",
    "wavfile.write('audio/mof.wav', Fs, tone*mod_wav)\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0+n_prev:x1+n_prev]*0.9, label=\"sig\")\n",
    "plt.plot(envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(all_mod[x0:x1]*0.9 + 1.0, label='mod')\n",
    "plt.title(\"envelope reconstruction\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_wav = np.array([[x]*noverlap for x in signal[n_prev:]]).flatten()\n",
    "sig_tone = np.sin(np.arange(len(sig_wav))*wt)\n",
    "wavfile.write('audio/ori.wav', Fs, sig_tone*sig_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder \n",
    "\n",
    "The decoder is built around a state machine that navigates in the \"Morse tree\":\n",
    "\n",
    "<img src=\"files/Morse1Min.gif\">\n",
    "\n",
    "\n",
    "  - The state is reset to `start` when a character trigger is received and the current character is appended to the result string\n",
    "  - A `dit` trigger moves the state to the right node in the tree and sets the current character\n",
    "  - A `dah` trigger moves the state to the left node in the tree and sets the current character\n",
    "  - If a `dit` or `dah` is received while on a leaf node the state is not moved\n",
    "  - The character corresponding to the `start` state is the unknown character `?`\n",
    "  - Some nodes do not correspond to any character. For these nodes the character attached is the unknown character `?`\n",
    "  - A `wrd` trigger resets the state to `start` and appends the space character to the result string\n",
    "  \n",
    "Triggers are defined on `dit`, `dah`, `chr` and `wrd` signals as positive edge triggers that default to `0.5` level. \n",
    "\n",
    "Some tricks are implemented:\n",
    "\n",
    "  - de-bouncing of signals by their expected lengths\n",
    "  - original dah sense signal is expected to be delayed by 2 dit lengths to recover their original starting moment. Assuming this condition treating dah in priority over dit helps in masking small dit re-bounce at start of original dah period.\n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Testing various trick options:\n",
    "\n",
    "-20 dB\n",
    "164 6 LE F4E XC AVV LE F4EXD ST4V DE EV5EPB 3V KE V HTETUB VVV DE G3ECLE4VF DIV43NI VVEU DS F4EX6 V44 DE FVETUL VVV NE FLNANI VVEEF D E PLKL 4V5 DEEF5EXL VVV DE UIEAEXB\n",
    "158 TV 6  F4EXB FVV  DE F4EX   4VV DE F4EXB  VV4 D  F4 E CB VLV CE F5EXL STV4 DE U 5EXB 4VV D E  4EXB VHV CE F4E XD V4V DE F5EXB VVV  DE G4ECB VRST DE F4XB   VV4 DE INSTEXB\n",
    "161 SE DI FSTEBD VV  DE F4ELB VVIA DE F4ETUB RVV DE F5EDTB EVVV DE F4EXB VVEA DE LVEXB  VV4 DE N4 EX6 VVV BE F4EXB  4VV DE F4EXB STVV DE F4EXB VVV  DE R 5EXB V5V H V 4EX <- shifted dah and all debounce \n",
    "162 SE DI FSTEXD VVW DE F4EXB VVIA DE F4ETUB KVV DE F4EDTB EVVV DE F4EXB VVEA DE LVEXB  VVV DE N4 EX6 VVV BE F4EXB  VVV DE F4EXB STVV DE F4EXB VVV  DE R 4EXB V5V H V 4EX <- with dah priority\n",
    "-17 dB\n",
    "153 V DE F4EXB VVV DE F4EX B VVV DE F4EXB 4VV  BE F4EBB   VVV DE F5EXB VVV DE V4EXB VVV DE F4EXB VVV DE F5EXB VVV DE V4EXB 4VV DE F4EXB VVV DE R4EXB VVV DE F4 X <- shifted dah and dah de-bounce\n",
    "153 V DE F4EXB VVV DE F4EX B VVV DE F4EXB 4VV  BE F4EBB   VVV DE F5EXB VVV DE V4EXB VVV DE F4EXB VVV DE F5EXB VVV DE V4EXB 4VV DE F4EXB VVV DE R4EXB VVV DE F4 X <- and all debounce\n",
    "154 V DE F4EXB UVV DE F4EXB  VVV DE F4EXB VV 4 DE R4EXB   VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB 4VV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV NE R4EXB VVV DE F4EX <- and dah priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoder:\n",
    "    def __init__(self, dit_length, dit_lvl=0.5, dah_lvl=0.5, chr_lvl=0.5, wrd_lvl=0.5):\n",
    "        self.dit_length = dit_length\n",
    "        self.dit_lvl = dit_lvl\n",
    "        self.dah_lvl = dah_lvl\n",
    "        self.chr_lvl = chr_lvl\n",
    "        self.wrd_lvl = wrd_lvl\n",
    "        self.prev_samples = None\n",
    "        self.result = \"\"\n",
    "        self.state = \"start\"\n",
    "        self.dit_count = 0\n",
    "        self.dah_count = 0\n",
    "        self.chr_count = 0\n",
    "        self.wrd_count = 0\n",
    "        self.morse_tree = {\n",
    "            \"start\": (\"T\", \"E\"),\n",
    "            \"T\": (\"M\", \"N\"),\n",
    "            \"E\": (\"A\", \"I\"),\n",
    "            \"M\": (\"O\", \"G\"),\n",
    "            \"N\": (\"K\", \"D\"),\n",
    "            \"A\": (\"W\", \"R\"),\n",
    "            \"I\": (\"U\", \"S\"),\n",
    "            \"O\": (\"Odash\", \"Odit\"),\n",
    "            \"G\": (\"Q\", \"Z\"),\n",
    "            \"K\": (\"Y\", \"C\"),\n",
    "            \"D\": (\"X\", \"B\"),\n",
    "            \"W\": (\"J\", \"P\"),\n",
    "            \"R\": (None, \"L\"),\n",
    "            \"U\": (\"Udash\", \"F\"),\n",
    "            \"S\": (\"V\", \"H\"),\n",
    "            \"Odash\": (\"0\", \"9\"),\n",
    "            \"Odit\": (None, \"8\"),\n",
    "            \"Q\": (None, None),\n",
    "            \"Z\": (None, \"7\"),\n",
    "            \"Y\": (None, None),\n",
    "            \"C\": (None, None),\n",
    "            \"X\": (None, None),\n",
    "            \"B\": (None, \"6\"),\n",
    "            \"J\": (\"1\", None),\n",
    "            \"P\": (None, None),\n",
    "            \"L\": (None, None),\n",
    "            \"Udash\": (\"2\", None),\n",
    "            \"F\": (None, None),\n",
    "            \"V\": (\"3\", None),\n",
    "            \"H\": (\"4\", \"5\"),\n",
    "            \"0\": (None, None),\n",
    "            \"1\": (None, None),\n",
    "            \"2\": (None, None),\n",
    "            \"3\": (None, None),\n",
    "            \"4\": (None, None),\n",
    "            \"5\": (None, None),\n",
    "            \"6\": (None, None),\n",
    "            \"7\": (None, None),\n",
    "            \"8\": (None, None),\n",
    "            \"9\": (None, None),\n",
    "        }\n",
    "        \n",
    "    def _dit_trig(self):\n",
    "        next_state = self.morse_tree[self.state][1] # right\n",
    "        if next_state is not None:\n",
    "            self.state = next_state\n",
    "        \n",
    "    def _dah_trig(self):\n",
    "        next_state = self.morse_tree[self.state][0] # left\n",
    "        if next_state is not None:\n",
    "            self.state = next_state\n",
    "    \n",
    "    def _chr_trig(self):\n",
    "        if len(self.state) == 1:\n",
    "            self.result += self.state\n",
    "        self.state = \"start\"\n",
    "        \n",
    "    def _wrd_trig(self):\n",
    "        self.result += \" \"\n",
    "        self.state = \"start\"\n",
    "    \n",
    "    def reset(self):\n",
    "        self.prev_samples = None\n",
    "        self.result = \"\"\n",
    "        self.state = \"start\"\n",
    "        self.dit_count = 0\n",
    "        self.dah_count = 0\n",
    "        self.chr_count = 0\n",
    "        self.wrd_count = 0\n",
    "            \n",
    "    def new_samples(self, samples):\n",
    "        if not self.prev_samples:\n",
    "            self.prev_samples = samples\n",
    "            return\n",
    "        # de-bouncing with 3 dits length (dah length) - priority to dah (mask false dit)\n",
    "        if self.dah_count > 3*self.dit_length and self.prev_samples[1] < self.dah_lvl and samples[1] >= self.dah_lvl:\n",
    "            self.dah_count = 0\n",
    "            self._dah_trig()\n",
    "        # de-bouncing with 1 dit length\n",
    "        elif self.dit_count > self.dit_length and self.prev_samples[0] < self.dit_lvl and samples[0] >= self.dit_lvl:\n",
    "            self.dit_count = 0\n",
    "            self._dit_trig()\n",
    "        # de-bouncing with 2 dits length (chr length = char separator - element separator)\n",
    "        if self.chr_count > 2*self.dit_length and self.prev_samples[2] < self.chr_lvl and samples[2] >= self.chr_lvl:\n",
    "            self.chr_count = 0\n",
    "            self._chr_trig()\n",
    "        # de-bouncing with 4 dits length (wrd length = word separator - chr separator - element separator)\n",
    "        if self.wrd_count > 4*self.dit_length and self.prev_samples[3] < self.wrd_lvl and samples[3] >= self.wrd_lvl:\n",
    "            self.wrd_count = 0\n",
    "            self._wrd_trig()\n",
    "        if self.dit_count <= self.dit_length:\n",
    "            self.dit_count += 1\n",
    "        if self.dah_count <= 3*self.dit_length:\n",
    "            self.dah_count += 1\n",
    "        if self.chr_count <= 2*self.dit_length:\n",
    "            self.chr_count += 1\n",
    "        if self.wrd_count <= 4*self.dit_length:\n",
    "            self.wrd_count += 1\n",
    "        self.prev_samples = samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(w_dits), type(w_dahs3), type(w_chrs), type(w_wrds))\n",
    "print(len(w_dits), len(w_dahs3), len(w_chrs), len(w_wrds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# will take delayed dah signal (thus shorter)\n",
    "w_len = np.min([len(w_dits), len(w_dahs3), len(w_chrs), len(w_wrds)])\n",
    "print(w_len)\n",
    "\n",
    "morse_decoder = MorseDecoder(dit_shift, chr_lvl=0.6)\n",
    "for i in range(w_len):\n",
    "    morse_decoder.new_samples([w_dits[i], w_dahs3[i], w_chrs[i], w_wrds[i]])\n",
    "result = morse_decoder.result\n",
    "result = re.sub(' +', ' ', result)\n",
    "print(len(result), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test signal reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = \"VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB\"\n",
    "test_keying_dataset = MorsekeyingDataset(morse_gen, device, -20, 132*5, 27*5, test_phrase, alphabet)\n",
    "test_keying_loader = torch.utils.data.DataLoader(test_keying_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dit_l = []\n",
    "p_dah_l = []\n",
    "p_ele_l = []\n",
    "p_chr_l = []\n",
    "p_wrd_l = []\n",
    "morse_key_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(test_keying_loader), total=len(test_keying_loader))\n",
    "for j, test in loop:\n",
    "    with torch.no_grad():\n",
    "        X_test = test[0]\n",
    "        pred_val = morse_key_model(X_test[0]).cpu()\n",
    "        p_dit_l.append(pred_val[0].item())\n",
    "        p_dah_l.append(pred_val[1].item())\n",
    "        p_ele_l.append(pred_val[2].item())\n",
    "        p_chr_l.append(pred_val[3].item())\n",
    "        p_wrd_l.append(pred_val[4].item())\n",
    "        \n",
    "p_dit = np.array(p_dit_l)\n",
    "p_dah = np.array(p_dah_l)\n",
    "p_ele = np.array(p_ele_l)\n",
    "p_chr = np.array(p_chr_l)\n",
    "p_wrd = np.array(p_wrd_l)\n",
    "\n",
    "# trim negative values\n",
    "p_dit[p_dit < 0] = 0\n",
    "p_dah[p_dah < 0] = 0\n",
    "p_ele[p_ele < 0] = 0\n",
    "p_chr[p_chr < 0] = 0\n",
    "p_wrd[p_wrd < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_signal = test_keying_dataset.get_signal()\n",
    "test_envelope = test_keying_dataset.get_envelope()\n",
    "\n",
    "elem_window = p_ele[dit_shift:]\n",
    "w_dits = p_dit[:-dit_shift] * elem_window\n",
    "w_dahs = p_dah[:-dit_shift] * elem_window\n",
    "w_dahs -= w_dits\n",
    "w_dahs2 = w_dahs[dah2_shift:]\n",
    "w_dahs3 = w_dahs[dah3_shift:]\n",
    "w_chrs = p_chr[dit_shift:]\n",
    "w_wrds = p_wrd[dit_shift:]\n",
    "\n",
    "w_dits *= 2.0\n",
    "w_dits[w_dits > 1.0] = 1.0\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(test_signal[x0+n_prev:x1+n_prev]*0.7, label=\"sig\")\n",
    "plt.plot(test_envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(w_dits[x0:x1]*0.9 + 1.0, label='dit')\n",
    "plt.plot(w_dahs[x0:x1]*0.9 + 1.0, label='dah')\n",
    "plt.plot(w_dahs2[x0:x1]*0.9 + 1.0, label='da2', alpha=0.5)\n",
    "plt.plot(w_dahs3[x0:x1]*0.9 + 1.0, label='da3', alpha=0.5)\n",
    "plt.plot(w_chrs[x0:x1]*0.9 + 2.0, label='chr')\n",
    "plt.plot(w_wrds[x0:x1]*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"Test keying - predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructed signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_len = min(len(w_dits), len(w_dahs), len(w_dahs2), len(w_dahs3))\n",
    "print(mod_len, noverlap, mod_len*noverlap)\n",
    "dit_mod = w_dits[:mod_len]\n",
    "dah_mod = w_dahs[:mod_len] + w_dahs2[:mod_len] + w_dahs3[:mod_len]\n",
    "all_mod = dit_mod + dah_mod\n",
    "mod_wav = np.array([[x]*noverlap for x in all_mod]).flatten()\n",
    "\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(mod_wav))*wt)\n",
    "\n",
    "wavfile.write('audio/moft.wav', Fs, tone*mod_wav)\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(test_signal[x0+n_prev:x1+n_prev]*0.7, label=\"sig\")\n",
    "plt.plot(test_envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(all_mod[x0:x1]*0.9 + 1.0, label='mod')\n",
    "plt.title(\"envelope reconstruction\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_wav = np.array([[x]*noverlap for x in test_signal[n_prev:]]).flatten()\n",
    "sig_tone = np.sin(np.arange(len(sig_wav))*wt)\n",
    "wavfile.write('audio/orit.wav', Fs, sig_tone*sig_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_len = min(len(w_dits), len(w_dahs3), len(w_dahs2), len(w_dahs3))\n",
    "morse_decoder = MorseDecoder(dit_shift, chr_lvl=0.7)\n",
    "for i in range(w_len):\n",
    "    morse_decoder.new_samples([w_dits[i], w_dahs3[i], w_chrs[i], w_wrds[i]]) # take delayed dah signal\n",
    "result = morse_decoder.result\n",
    "result = re.sub(' +', ' ', result)\n",
    "print(len(result), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
