{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morse keying recognition using 1D Convolutional Neural Network\n",
    "\n",
    "In this playbook we will try 1D CNN in place of the LSTM RNN to perform Morse keying features recognition (dits, dahs and various silences). The first cells to prepare the data are similar to those already developed for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create string\n",
    "\n",
    "Each character in the alphabet should happen a large enough number of times. As a rule of thumb we will take some multiple of the number of characters in the alphabet. If the multiplier is large enough the probability of each character appearance will be even over the alphabet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "\n",
    "morse_gen = MorseGen.Morse()\n",
    "alphabet = morse_gen.alphabet36\n",
    "print(132/len(alphabet))\n",
    "\n",
    "morsestr = MorseGen.get_morse_str(nchars=132*2, nwords=27*2, chars=alphabet)\n",
    "print(alphabet)\n",
    "print(len(morsestr), morsestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframe and extract envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 8000\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*19) + 1\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim_str(morsestr, samples_per_dit, 128, alphabet)\n",
    "env = label_df['env'].to_numpy()\n",
    "print(type(env), len(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_new_data(morse_gen, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "    if not phrase:\n",
    "        phrase = MorseGen.get_morse_str(nchars=nchars, nwords=nwords, chars=alphabet)\n",
    "    print(len(phrase), phrase)\n",
    "    Fs = 8000\n",
    "    samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "    n_prev = int((samples_per_dit/128)*19) + 1 # number of samples to look back is slightly more than a dit-dah and a word space (2+3+7=12)\n",
    "    print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "    label_df = morse_gen.encode_df_decim_str(phrase, samples_per_dit, 128, alphabet)\n",
    "    # extract the envelope\n",
    "    envelope = label_df['env'].to_numpy()\n",
    "    # remove the envelope\n",
    "    label_df.drop(columns=['env'], inplace=True)\n",
    "    SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "    SNR_linear *= 256 # Apply original FFT\n",
    "    print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "    t = np.linspace(0, len(envelope)-1, len(envelope))\n",
    "    power = np.sum(envelope**2)/len(envelope)\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(envelope))\n",
    "    # noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "    signal = (envelope + noise)**2\n",
    "    signal[signal > 1.0] = 1.0 # a bit crap ...\n",
    "    return envelope, signal, label_df, n_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "envelope, signal, label_df, n_prev = get_new_data(morse_gen, SNR_dB=-17, phrase=morsestr, alphabet=alphabet)\n",
    "\n",
    "# Show\n",
    "print(n_prev)\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "print(max(signal))\n",
    "    \n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0:x1]*0.9, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 1.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 2.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 2.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"signal and keying labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader for keying model\n",
    "### Define keying dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MorsekeyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, morse_gen, device, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "        self.envelope, self.signal, self.label_df0, self.seq_len = get_new_data(morse_gen, SNR_dB=SNR_dB, phrase=phrase, alphabet=alphabet)\n",
    "        self.label_df = self.label_df0[['dit','dah','ele','chr','wrd']]\n",
    "        self.X = torch.FloatTensor(self.signal).to(device)\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_envelope(self):\n",
    "        return self.envelope\n",
    "    \n",
    "    def get_signal(self):\n",
    "        return self.signal\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_labels0(self):\n",
    "        return self.label_df0\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keying data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_keying_dataset = MorsekeyingDataset(morse_gen, device, -20, 132*5, 27*5, morsestr, alphabet)\n",
    "train_keying_loader = torch.utils.data.DataLoader(train_keying_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = train_keying_dataset.get_signal()\n",
    "signal = (signal - min(signal))\n",
    "label_df = train_keying_dataset.get_labels()\n",
    "label_df0 = train_keying_dataset.get_labels0()\n",
    "\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0:x1]*0.9, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 1.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 2.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 2.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"keying - signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model classes\n",
    "\n",
    "The model classes are the same they will be instantiated differently for keying and character models \n",
    "\n",
    "### Create model for keying recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "cnn = nn.Conv1d(in_channels=1, out_channels=7, kernel_size=3, stride=1)\n",
    "lin = nn.Linear(7, 5)\n",
    "input_1d = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "seq_len = print(len(input_1d))\n",
    "input_1d = input_1d.unsqueeze(0).unsqueeze(0)\n",
    "print(input_1d.shape)\n",
    "out = cnn(input_1d)\n",
    "print(out.shape)\n",
    "out = out.reshape(1,8,7)\n",
    "print(out.shape)\n",
    "out = lin(out)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "# print(cnn1d__y1[-1].shape)\n",
    "# print(cnn1d__y1[:,:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=1, hidden_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseCNN(nn.Module):\n",
    "    def __init__(self, device, input_size=1, output_size=5, seq_len=70, stride=1):\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.cnn = torch.nn.Conv1d(in_channels=input_size, out_channels=output_size, kernel_size=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
