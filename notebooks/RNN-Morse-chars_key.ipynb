{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with character recognition - keying recognition based\n",
    "\n",
    "Builds on `RNN-Morse-chars-feat` and post processes the keying recognition (dits, dahs and silences) to best reveal dits, dots and character and word separators. Then it can be processed by a programmatic logic or another RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create string\n",
    "\n",
    "Each character in the alphabet should happen a large enough number of times. As a rule of thumb we will take some multiple of the number of characters in the alphabet. If the multiplier is large enough the probability of each character appearance will be even over the alphabet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "\n",
    "morse_gen = MorseGen.Morse()\n",
    "alphabet = morse_gen.alphabet14\n",
    "print(132/len(alphabet))\n",
    "\n",
    "morsestr = MorseGen.get_morse_str(nchars=132*5, nwords=27*5, chars=alphabet)\n",
    "print(alphabet)\n",
    "print(len(morsestr), morsestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframe and extract envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 8000\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*12*2) + 1\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim_str(morsestr, samples_per_dit, 128, alphabet)\n",
    "env = label_df['env'].to_numpy()\n",
    "print(type(env), len(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_new_data(morse_gen, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "    if not phrase:\n",
    "        phrase = MorseGen.get_morse_str(nchars=nchars, nwords=nwords, chars=alphabet)\n",
    "    print(len(phrase), phrase)\n",
    "    Fs = 8000\n",
    "    samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "    n_prev = int((samples_per_dit/128)*27) + 1 # number of samples to look back is slightly more than a dit-dah and a word space (2+3+7=12)\n",
    "    print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "    label_df = morse_gen.encode_df_decim_str(phrase, samples_per_dit, 128, alphabet)\n",
    "    # extract the envelope\n",
    "    envelope = label_df['env'].to_numpy()\n",
    "    # remove the envelope\n",
    "    label_df.drop(columns=['env'], inplace=True)\n",
    "    SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "    SNR_linear *= 256 # Apply original FFT\n",
    "    print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "    t = np.linspace(0, len(envelope)-1, len(envelope))\n",
    "    power = np.sum(envelope**2)/len(envelope)\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(envelope))\n",
    "    # noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "    signal = envelope + noise\n",
    "    return envelope, signal, label_df, n_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "envelope, signal, label_df, n_prev = get_new_data(morse_gen, SNR_dB=-17, phrase=morsestr, alphabet=alphabet)\n",
    "\n",
    "# Show\n",
    "print(n_prev)\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "    \n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,3+0.5*len(morse_gen.alphabet)))\n",
    "plt.plot(signal[x0:x1]*0.5, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 1.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 2.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 2.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 2.0, label='wrd')\n",
    "for i, a in enumerate(alphabet):\n",
    "    plt.plot(label_df[x0:x1][a]*0.9 + 3.0 + i, label=a)\n",
    "plt.title(\"signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader for keying model\n",
    "### Define keying dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MorsekeyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, morse_gen, device, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "        self.envelope, self.signal, self.label_df0, self.seq_len = get_new_data(morse_gen, SNR_dB=SNR_dB, phrase=phrase, alphabet=alphabet)\n",
    "        self.label_df = self.label_df0[['dit','dah','ele','chr','wrd']]\n",
    "        self.X = torch.FloatTensor(self.signal).to(device)\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_envelope(self):\n",
    "        return self.envelope\n",
    "    \n",
    "    def get_signal(self):\n",
    "        return self.signal\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_labels0(self):\n",
    "        return self.label_df0\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keying data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_keying_dataset = MorsekeyingDataset(morse_gen, device, -23, 132*5, 27*5, morsestr, alphabet)\n",
    "train_keying_loader = torch.utils.data.DataLoader(train_keying_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = train_keying_dataset.get_signal()\n",
    "label_df = train_keying_dataset.get_labels()\n",
    "label_df0 = train_keying_dataset.get_labels0()\n",
    "\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,3))\n",
    "plt.plot(signal[x0:x1]*0.5, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 1.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 2.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 2.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"keying - signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model classes\n",
    "\n",
    "The model classes are the same they will be instantiated differently for keying and character models \n",
    "\n",
    "### Create model for keying recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseBatchedLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "        self.m = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        #print(len(input_seq), input_seq.shape, input_seq.view(-1, 1, 1).shape)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(-1, 1, self.input_size), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return self.m(predictions[-1])\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )     \n",
    "    \n",
    "class MorseLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the keying model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_key_model = MorseBatchedLSTM(device, hidden_layer_size=7, output_size=5).to(device) # This is the only way to get things work properly with device\n",
    "morse_key_loss_function = nn.MSELoss()\n",
    "morse_key_optimizer = torch.optim.Adam(morse_key_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_key_model)\n",
    "print(morse_key_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_key_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand(n_prev)\n",
    "#X_t = torch.tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385])\n",
    "X_t = X_t.cuda()\n",
    "print(\"Input shape\", X_t.shape, X_t.view(-1, 1, 1).shape)\n",
    "print(X_t)\n",
    "morse_key_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "channels=10\n",
    "H=n_prev\n",
    "W=1\n",
    "torchinfo.summary(morse_key_model, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train keying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_keying_loader)\n",
    "X, y = next(it)\n",
    "print(X.reshape(n_prev,1).shape, X[0].shape, y[0].shape)\n",
    "print(X[0], y[0])\n",
    "X, y = next(it)\n",
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epochs = 2\n",
    "morse_key_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_losses = []\n",
    "    loop = tqdm(enumerate(train_keying_loader), total=len(train_keying_loader), leave=True)\n",
    "    for j, train in loop:\n",
    "        X_train = train[0][0]\n",
    "        y_train = train[1][0]\n",
    "        morse_key_optimizer.zero_grad()\n",
    "        if morse_key_model.__class__.__name__ in [\"MorseLSTM\", \"MorseLSTM2\", \"MorseBatchedLSTM\", \"MorseBatchedLSTM2\"]:\n",
    "            morse_key_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_key_model(X_train)\n",
    "        single_loss = morse_key_loss_function(y_pred, y_train)\n",
    "        single_loss.backward()\n",
    "        morse_key_optimizer.step()\n",
    "        train_losses.append(single_loss.item())\n",
    "        # update progress bar\n",
    "        if j % 1000 == 0:\n",
    "            loop.set_description(f\"Epoch [{i+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=np.mean(train_losses))\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {np.mean(train_losses):6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model: \n",
    "    torch.save(morse_key_model.state_dict(), 'models/morse_key_model')\n",
    "else:\n",
    "    morse_key_model.load_state_dict(torch.load('models/morse_key_model', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results for next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_key_train = torch.empty(1,5).to(device)\n",
    "morse_key_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(train_keying_loader), total=len(train_keying_loader))\n",
    "for j, train in loop:\n",
    "    with torch.no_grad():\n",
    "        X_train = train[0]\n",
    "        pred_val = morse_key_model(X_train[0])\n",
    "        p_key_train = torch.cat([p_key_train, pred_val.reshape(1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first garbage sample\n",
    "p_key_train = p_key_train[1:]\n",
    "print(p_key_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_key_train[0:2])\n",
    "p_dits = p_key_train[:,0].to('cpu').numpy()\n",
    "p_dahs = p_key_train[:,1].to('cpu').numpy()\n",
    "p_eles = p_key_train[:,2].to('cpu').numpy()\n",
    "p_chrs = p_key_train[:,3].to('cpu').numpy()\n",
    "p_wrds = p_key_train[:,4].to('cpu').numpy()\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0+n_prev:x1+n_prev]*0.5, label=\"sig\")\n",
    "plt.plot(envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(p_dits[x0:x1]*0.9 + 1.0, label='dit')\n",
    "plt.plot(p_dahs[x0:x1]*0.9 + 1.0, label='dah')\n",
    "plt.plot(p_eles[x0:x1]*0.9 + 2.0, label='ele')\n",
    "plt.plot(p_chrs[x0:x1]*0.9 + 2.0, label='chr')\n",
    "plt.plot(p_wrds[x0:x1]*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"keying - predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit_shift = round(samples_per_dit / 128)\n",
    "dit2_shift = round(samples_per_dit / 64)\n",
    "dit3_shift = round(samples_per_dit / 32)\n",
    "print(dit_shift, dit2_shift, dit3_shift)\n",
    "dah2_shift = dit2_shift - dit_shift\n",
    "dah3_shift = dit3_shift - dit2_shift\n",
    "print(dah_shift, dah2_shift)\n",
    "\n",
    "elem_window = p_eles[dit_shift:]\n",
    "w_dits = p_dits[:-dit_shift] * elem_window\n",
    "w_dahs = p_dahs[:-dit_shift] * elem_window\n",
    "w_dahs -= w_dits\n",
    "w_dahs2 = w_dahs[dah2_shift:]\n",
    "w_dahs3 = w_dahs[dah3_shift:]\n",
    "\n",
    "w_dits *= 2.5\n",
    "w_dits[w_dits > 1.0] = 1.0\n",
    "\n",
    "label_char_df = train_keying_dataset.get_labels0().drop(columns=['dit','dah','ele','chr','wrd'])\n",
    "label_char_df = label_char_df[n_prev:].reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(50,6+0.5*len(alphabet)))\n",
    "plt.plot(signal[x0+n_prev:x1+n_prev]*0.5, label=\"sig\")\n",
    "plt.plot(envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(w_dits[x0:x1]*0.9 + 1.0, label='dit')\n",
    "plt.plot(w_dahs[x0:x1]*0.9 + 1.0, label='dah')\n",
    "plt.plot(w_dahs2[x0:x1]*0.9 + 1.0, label='da2', alpha=0.5)\n",
    "plt.plot(w_dahs3[x0:x1]*0.9 + 1.0, label='da3', alpha=0.5)\n",
    "#plt.plot(p_eles[x0+dit_shift:x1+dit_shift]*0.9 + 2.0, label='ele')\n",
    "plt.plot(p_chrs[x0+dit_shift:x1+dit_shift]*0.9 + 2.0, label='chr')\n",
    "plt.plot(p_wrds[x0+dit_shift:x1+dit_shift]*0.9 + 2.0, label='wrd')\n",
    "for i, a in enumerate(alphabet):\n",
    "    plt.plot(label_char_df[x0:x1][a]*0.45 + 3.0 + i, label=a)\n",
    "plt.title(\"keying - predictions - character labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi frequency reconstruction\n",
    "\n",
    "The idea is to use the resulting dits and dahs sense signals in their original shape. The lengths of dits and dahs are therefore similar. To help distinguish between them by ear one would assign a higher pitch to the dits (thus mimicking the \"i\" of the dit) and a lower pitch to the dahs (thus mimicking the \"ah\" of the dah). Moreover to reconstruct the rhythm the dahs sense is delayed by two dits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.special\n",
    "from scipy.io import wavfile\n",
    "\n",
    "Fdah = 440 # A4\n",
    "Fdit = 523 # C5\n",
    "Fs = 8000\n",
    "noverlap = 128\n",
    "decim = 128\n",
    "\n",
    "dit_mod = w_dits[:-dah3_shift]\n",
    "dit_wav = np.array([[x]*noverlap for x in dit_mod]).flatten()\n",
    "dah_mod = w_dahs3\n",
    "dah_wav = np.array([[x]*noverlap for x in dah_mod]).flatten()\n",
    "\n",
    "dit_wt = (Fdit / Fs)*2*np.pi\n",
    "dah_wt = (Fdah / Fs)*2*np.pi\n",
    "dit_tone = np.sin(np.arange(len(dit_wav))*dit_wt)\n",
    "dah_tone = np.sin(np.arange(len(dah_wav))*dah_wt)\n",
    "\n",
    "wavfile.write('audio/bif.wav', Fs, dit_tone*dit_wav + dah_tone*dah_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mono frequency reconstruction\n",
    "\n",
    "Here we stick to more convenient Morse code. In order to do so 2 delayed copies of the dahs sense signal are summed to reconstruct the length of an original dah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fcode = 523\n",
    "\n",
    "mod_len = min(len(w_dits), len(w_dahs), len(w_dahs2), len(w_dahs3))\n",
    "dit_mod = w_dits[:mod_len]\n",
    "dah_mod = w_dahs[:mod_len] + w_dahs2[:mod_len] + w_dahs3[:mod_len]\n",
    "all_mod = dit_mod + dah_mod\n",
    "mod_wav = np.array([[x]*noverlap for x in all_mod]).flatten()\n",
    "\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(dit_wav))*wt)\n",
    "\n",
    "wavfile.write('audio/mof.wav', Fs, tone*mod_wav)\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0+n_prev:x1+n_prev]*0.5, label=\"sig\")\n",
    "plt.plot(envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(all_mod[x0:x1]*0.9 + 1.0, label='mod')\n",
    "plt.title(\"envelope reconstruction\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct datasets for character model\n",
    "\n",
    "`label_char_df` are already the correct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = torch.FloatTensor(w_dits).reshape(len(w_dits),1)\n",
    "t1 = torch.FloatTensor(w_dahs).reshape(len(w_dahs),1)\n",
    "t2 = torch.FloatTensor(p_chrs[dit_shift:]).reshape(len(w_dahs),1)\n",
    "t3 = torch.FloatTensor(p_wrds[dit_shift:]).reshape(len(w_dahs),1)\n",
    "p_key_train = torch.cat([t0,t1,t2,t3], axis=1)\n",
    "p_key_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader for character model\n",
    "### Define character dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseCharacterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, key_train, label_df, seq_len):\n",
    "        self.label_df = label_df\n",
    "        self.X = key_train.to(device)\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_X(self):\n",
    "        return self.X\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define character data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_character_dataset = MorseCharacterDataset(p_key_train[dit_shift:], label_char_df, n_prev)\n",
    "train_character_loader = torch.utils.data.DataLoader(train_character_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chr = train_character_dataset.get_X().cpu()\n",
    "label_df_chr = train_character_dataset.get_labels()\n",
    "\n",
    "print(type(X_train_chr), X_train_chr.shape)\n",
    "print(type(label_df_chr), label_df_chr.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,3+0.5*len(alphabet)))\n",
    "plt.plot(X_train_chr[x0:x1,0], label='dit')\n",
    "plt.plot(X_train_chr[x0:x1,1], label='dah')\n",
    "plt.plot(X_train_chr[x0:x1,2] + 1.0, label='chr')\n",
    "plt.plot(X_train_chr[x0:x1,3] + 1.0, label='wrd')\n",
    "for i, a in enumerate(alphabet):\n",
    "    plt.plot(label_df_chr[x0:x1][a]*0.9 + 2.0 + i, label=a)\n",
    "plt.title(\"character - signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model for character recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_chr_model = MorseBatchedLSTM(device, input_size=4, hidden_layer_size=len(alphabet)*2, output_size=len(alphabet)).to(device) # This is the only way to get things work properly with device\n",
    "morse_chr_loss_function = nn.MSELoss()\n",
    "morse_chr_optimizer = torch.optim.Adam(morse_chr_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_chr_model)\n",
    "print(morse_chr_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_chr_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand(n_prev, 4)\n",
    "#X_t = torch.tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385])\n",
    "X_t = X_t.cuda()\n",
    "print(\"Input shape\", X_t.shape, X_t.view(-1, 1, 4).shape)\n",
    "morse_chr_model(X_t)\n",
    "# Does not work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=10\n",
    "H=n_prev\n",
    "W=4\n",
    "torchinfo.summary(morse_chr_model, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train character model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_character_loader)\n",
    "X, y = next(it)\n",
    "print(X.reshape(n_prev,4).shape, X[0].shape, y[0].shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "morse_chr_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_losses = []\n",
    "    loop = tqdm(enumerate(train_character_loader), total=len(train_character_loader), leave=True)\n",
    "    for j, train in loop:\n",
    "        X_train = train[0][0]\n",
    "        y_train = train[1][0]\n",
    "        morse_chr_optimizer.zero_grad()\n",
    "        if morse_chr_model.__class__.__name__ in [\"MorseLSTM\", \"MorseLSTM2\", \"MorseBatchedLSTM\", \"MorseBatchedLSTM2\"]:\n",
    "            morse_chr_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_chr_model(X_train)\n",
    "        single_loss = morse_chr_loss_function(y_pred, y_train)\n",
    "        single_loss.backward()\n",
    "        morse_chr_optimizer.step()\n",
    "        train_losses.append(single_loss.item())\n",
    "        # update progress bar\n",
    "        if j % 1000 == 0:\n",
    "            loop.set_description(f\"Epoch [{i+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=np.mean(train_losses))\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {np.mean(train_losses):6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_alpha = {}\n",
    "for a in alphabet:\n",
    "    p_alpha[a] = []\n",
    "morse_chr_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(train_character_loader), total=len(train_character_loader))\n",
    "for j, train in loop:\n",
    "    with torch.no_grad():\n",
    "        X_chr = train[0][0]\n",
    "        pred_val = morse_chr_model(X_chr).cpu()\n",
    "        for i, a in enumerate(alphabet):\n",
    "            p_alpha[a].append(pred_val[i].item())\n",
    "        \n",
    "for a in alphabet:\n",
    "    p_alpha[a] = np.array(p_alpha[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_alpha = label_df_chr[n_prev:].reset_index(drop=True)\n",
    "plt.figure(figsize=(50,3+0.5*len(morse_gen.alphabet)))\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev, 0], label='dit')\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev, 1], label='dah')\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev, 2] + 1.0, label='chr')\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev, 3] + 1.0, label='wrd')\n",
    "for i, a in enumerate(alphabet):\n",
    "    plt.plot(p_alpha[a][x0:x1]*0.9 + 2.0 + i, label=a+\"p\")\n",
    "    plt.plot(l_alpha[a][x0:x1]*0.9 + 2.0 + i, label=a+\"l\")\n",
    "plt.title(\"predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
