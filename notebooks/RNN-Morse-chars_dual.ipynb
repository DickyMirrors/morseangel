{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with character recognition - dual model\n",
    "\n",
    "Builds on `RNN-Morse-chars-feat` but creates two models. One will deal with keying recognition (dits, dahs and silences) then its output will be used to feed a second model dedicated to character recognition. Both models are trained using the same base data but trainings are (of course) done separately.\n",
    "\n",
    "It looks like this one is working! See explanation on character labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create string\n",
    "\n",
    "Each character in the alphabet should happen a large enough number of times. As a rule of thumb we will take some multiple of the number of characters in the alphabet. If the multiplier is large enough the probability of each character appearance will be even over the alphabet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "\n",
    "morse_gen = MorseGen.Morse()\n",
    "alphabet = morse_gen.alphabet14\n",
    "print(132/len(alphabet))\n",
    "\n",
    "morsestr = MorseGen.get_morse_str(nchars=132*5, nwords=27*5, chars=alphabet)\n",
    "print(alphabet)\n",
    "print(len(morsestr), morsestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframe and extract envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 8000\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*12*2) + 1\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim_str(morsestr, samples_per_dit, 128, alphabet)\n",
    "env = label_df['env'].to_numpy()\n",
    "print(type(env), len(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_new_data(morse_gen, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "    if not phrase:\n",
    "        phrase = MorseGen.get_morse_str(nchars=nchars, nwords=nwords, chars=alphabet)\n",
    "    print(len(phrase), phrase)\n",
    "    Fs = 8000\n",
    "    samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "    n_prev = int((samples_per_dit/128)*19) + 1 # number of samples to look back is slightly more than a \"O\" a word space (2+3+7=12)\n",
    "    print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "    label_df = morse_gen.encode_df_decim_tree(phrase, samples_per_dit, 128, alphabet)\n",
    "    # extract the envelope\n",
    "    envelope = label_df['env'].to_numpy()\n",
    "    # remove the envelope\n",
    "    label_df.drop(columns=['env'], inplace=True)\n",
    "    SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "    SNR_linear *= 256 # Apply original FFT\n",
    "    print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "    t = np.linspace(0, len(envelope)-1, len(envelope))\n",
    "    power = np.sum(envelope**2)/len(envelope)\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(envelope))\n",
    "    # noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "    signal = (envelope + noise)**2\n",
    "    signal[signal > 1.0] = 1.0 # a bit crap ...\n",
    "    return envelope, signal, label_df, n_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "envelope, signal, label_df, n_prev = get_new_data(morse_gen, SNR_dB=-17, phrase=morsestr, alphabet=alphabet)\n",
    "\n",
    "# Show\n",
    "print(n_prev)\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "    \n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,4+0.5*len(morse_gen.alphabet)))\n",
    "plt.plot(signal[x0:x1]*0.7, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 1.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 2.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 2.0, label='chr', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 2.0, label='wrd')\n",
    "plt.plot(label_df[x0:x1].nul*0.9 + 3.0, label='nul')\n",
    "for i, a in enumerate(alphabet):\n",
    "    plt.plot(label_df[x0:x1][a]*0.9 + 4.0 + i, label=a)\n",
    "plt.title(\"signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader for keying model\n",
    "### Define keying dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MorsekeyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, morse_gen, device, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "        self.envelope, self.signal, self.label_df0, self.seq_len = get_new_data(morse_gen, SNR_dB=SNR_dB, phrase=phrase, alphabet=alphabet)\n",
    "        self.label_df = self.label_df0[['dit','dah','ele','chr','wrd']]\n",
    "        self.X = torch.FloatTensor(self.signal).to(device)\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_envelope(self):\n",
    "        return self.envelope\n",
    "    \n",
    "    def get_signal(self):\n",
    "        return self.signal\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_labels0(self):\n",
    "        return self.label_df0\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keying data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_keying_dataset = MorsekeyingDataset(morse_gen, device, -20, 132*5, 27*5, morsestr, alphabet)\n",
    "train_keying_loader = torch.utils.data.DataLoader(train_keying_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = train_keying_dataset.get_signal()\n",
    "envelope = train_keying_dataset.get_envelope()\n",
    "label_df = train_keying_dataset.get_labels()\n",
    "label_df0 = train_keying_dataset.get_labels0()\n",
    "\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,3))\n",
    "plt.plot(signal[x0:x1]*0.5, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 1.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 2.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 2.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 2.0, label='wrd')\n",
    "plt.title(\"keying - signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model classes\n",
    "\n",
    "The model classes are the same they will be instantiated differently for keying and character models \n",
    "\n",
    "### Create model for keying recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseBatchedLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "        self.m = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        #print(len(input_seq), input_seq.shape, input_seq.view(-1, 1, 1).shape)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(-1, 1, self.input_size), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )     \n",
    "    \n",
    "class MorseLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the keying model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_key_model = MorseBatchedLSTM(device, hidden_layer_size=7, output_size=5).to(device) # This is the only way to get things work properly with device\n",
    "morse_key_loss_function = nn.MSELoss()\n",
    "morse_key_optimizer = torch.optim.Adam(morse_key_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_key_model)\n",
    "print(morse_key_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_key_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand(n_prev)\n",
    "#X_t = torch.tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385])\n",
    "X_t = X_t.cuda()\n",
    "print(\"Input shape\", X_t.shape, X_t.view(-1, 1, 1).shape)\n",
    "print(X_t)\n",
    "morse_key_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "channels=10\n",
    "H=n_prev\n",
    "W=1\n",
    "torchinfo.summary(morse_key_model, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train keying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_keying_loader)\n",
    "X, y = next(it)\n",
    "print(X.reshape(n_prev,1).shape, X[0].shape, y[0].shape)\n",
    "print(X[0], y[0])\n",
    "X, y = next(it)\n",
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epochs = 4\n",
    "morse_key_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_losses = []\n",
    "    loop = tqdm(enumerate(train_keying_loader), total=len(train_keying_loader), leave=True)\n",
    "    for j, train in loop:\n",
    "        X_train = train[0][0]\n",
    "        y_train = train[1][0]\n",
    "        morse_key_optimizer.zero_grad()\n",
    "        if morse_key_model.__class__.__name__ in [\"MorseLSTM\", \"MorseLSTM2\", \"MorseBatchedLSTM\", \"MorseBatchedLSTM2\"]:\n",
    "            morse_key_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_key_model(X_train)\n",
    "        single_loss = morse_key_loss_function(y_pred, y_train)\n",
    "        single_loss.backward()\n",
    "        morse_key_optimizer.step()\n",
    "        train_losses.append(single_loss.item())\n",
    "        # update progress bar\n",
    "        if j % 1000 == 0:\n",
    "            loop.set_description(f\"Epoch [{i+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=np.mean(train_losses))\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {np.mean(train_losses):6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model: \n",
    "    torch.save(morse_key_model.state_dict(), 'models/morse_key_model')\n",
    "else:\n",
    "    morse_key_model.load_state_dict(torch.load('models/morse_key_model', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract results for next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "p_key_train = torch.empty(1,5).to(device)\n",
    "morse_key_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(train_keying_loader), total=len(train_keying_loader))\n",
    "for j, train in loop:\n",
    "    with torch.no_grad():\n",
    "        X_train = train[0]\n",
    "        pred_val = morse_key_model(X_train[0])\n",
    "        p_key_train = torch.cat([p_key_train, pred_val.reshape(1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first garbage sample\n",
    "p_key_train = p_key_train[1:]\n",
    "print(p_key_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_key_train[0:2])\n",
    "p_dits = p_key_train[:,0].to('cpu').numpy()\n",
    "p_dahs = p_key_train[:,1].to('cpu').numpy()\n",
    "p_eles = p_key_train[:,2].to('cpu').numpy()\n",
    "p_chrs = p_key_train[:,3].to('cpu').numpy()\n",
    "p_wrds = p_key_train[:,4].to('cpu').numpy()\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0+n_prev:x1+n_prev]*0.5, label=\"sig\")\n",
    "plt.plot(envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(p_dits[x0:x1]*0.9 + 1.0, label='dit')\n",
    "plt.plot(p_dahs[x0:x1]*0.9 + 1.0, label='dah')\n",
    "plt.plot(p_eles[x0:x1]*0.9 + 2.0, label='ele', color='orange')\n",
    "plt.plot(p_chrs[x0:x1]*0.9 + 2.0, label='chr')\n",
    "plt.plot(p_wrds[x0:x1]*0.9 + 2.0, label='wrd', color='green')\n",
    "plt.title(\"keying - predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post process\n",
    "\n",
    "  - Take softmax\n",
    "  - Subtract dit from dah\n",
    "  - Shift dit, ele, chr and wrd so the bottom is approximately zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = nn.Softmax(dim=1)\n",
    "p_sm_train = sm(p_key_train)\n",
    "p_sm_train[:,1] -= p_sm_train[:,0]\n",
    "p_sm_train[:,0] = p_sm_train[:,0]*2.0 - 0.25\n",
    "p_sm_train[:,2] -= 0.125\n",
    "p_sm_train[:,3] -= 0.125\n",
    "p_sm_train[:,4] -= 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sm_dits = p_sm_train[:,0].to('cpu').numpy()\n",
    "p_sm_dahs = p_sm_train[:,1].to('cpu').numpy()\n",
    "p_sm_eles = p_sm_train[:,2].to('cpu').numpy()\n",
    "p_sm_chrs = p_sm_train[:,3].to('cpu').numpy()\n",
    "p_sm_wrds = p_sm_train[:,4].to('cpu').numpy()\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0+n_prev:x1+n_prev]*0.5, label=\"sig\")\n",
    "plt.plot(envelope[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(p_sm_dits[x0:x1] + 1.0, label='dit')\n",
    "plt.plot(p_sm_dahs[x0:x1] + 1.0, label='dah')\n",
    "plt.plot(p_sm_eles[x0:x1] + 2.0, label='ele', color='orange')\n",
    "plt.plot(p_sm_chrs[x0:x1] + 2.0, label='chr')\n",
    "plt.plot(p_sm_wrds[x0:x1] + 2.0, label='wrd', color='green')\n",
    "plt.title(\"keying - softmax predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader for character model\n",
    "\n",
    "The key to successful decoding lies in following the Morse tree as you would do in procedural programming (see `RNN-Morse-chars-hyb` that already produces significant results). Thie is the \"Morse tree\":\n",
    "\n",
    "<img src=\"files/Morse1Min.gif\">\n",
    "\n",
    "The root of the tree is the \"start\" state. At each character break the current state is reset at \"start\" state. Then at each new element (dit or dah) the state moves to the next node on the left (dah) or the right (dit) and the character decoded so far is simply attached to the node. The actual decoded character is the one attached to the node of the current state right before it is reset to \"start\" by the character separator.\n",
    "\n",
    "There is one label per character plus a \"nul\" character for characters that are not recognized by any state (some nodes do not yield any useful character and are just intermediate nodes). To build the labels one simply follows the logic described above. In addition the character label is extended to the next \"ele\" and \"chr\" periods. \n",
    "\n",
    "To get the final result the character lines are multiplied (gated) by the character separator line (\"chr\") the most probable character is then the one with maximum value.\n",
    "\n",
    "### Define character dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseCharacterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, key_train, label_df, seq_len):\n",
    "        self.label_df = label_df.drop(columns=['dit','dah'])\n",
    "        self.X = key_train\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_X(self):\n",
    "        return self.X\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define character data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_character_dataset = MorseCharacterDataset(p_sm_train, label_df0[n_prev:].reset_index(drop=True), n_prev)\n",
    "train_character_loader = torch.utils.data.DataLoader(train_character_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chr = train_character_dataset.get_X().cpu()\n",
    "label_df_chr = train_character_dataset.get_labels()\n",
    "\n",
    "print(type(X_train_chr), X_train_chr.shape)\n",
    "print(type(label_df_chr), label_df_chr.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,3+0.5*len(alphabet)))\n",
    "plt.plot(X_train_chr[x0:x1,0], label='Xdit')\n",
    "plt.plot(X_train_chr[x0:x1,1], label='Xdah')\n",
    "plt.plot(X_train_chr[x0:x1,3] + 1.0, label='Xchr')\n",
    "plt.plot(label_df_chr[x0:x1]['ele']*0.9 + 2.0, label='ele', color=\"orange\")\n",
    "plt.plot(label_df_chr[x0:x1]['chr']*0.9 + 2.0, label='chr')\n",
    "plt.plot(label_df_chr[x0:x1]['wrd']*0.9 + 2.0, label='wrd')\n",
    "for i, a in enumerate(alphabet):\n",
    "    plt.plot(label_df_chr[x0:x1][a]*0.9 + 3.0 + i, label=a)\n",
    "plt.title(\"character - signal and labels\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model for character recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_chr_model = MorseBatchedLSTM(device, input_size=5, hidden_layer_size=len(alphabet)*2, output_size=len(alphabet)+4).to(device) # This is the only way to get things work properly with device\n",
    "morse_chr_loss_function = nn.MSELoss()\n",
    "morse_chr_optimizer = torch.optim.Adam(morse_chr_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_chr_model)\n",
    "print(morse_chr_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_chr_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand(n_prev, 5)\n",
    "#X_t = torch.tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385])\n",
    "X_t = X_t.cuda()\n",
    "print(\"Input shape\", X_t.shape, X_t.view(-1, 1, 5).shape)\n",
    "morse_chr_model(X_t)\n",
    "# Does not work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=10\n",
    "H=n_prev\n",
    "W=5\n",
    "torchinfo.summary(morse_chr_model, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train character model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_character_loader)\n",
    "X, y = next(it)\n",
    "print(X.reshape(n_prev,5).shape, X[0].shape, y[0].shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "morse_chr_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_losses = []\n",
    "    loop = tqdm(enumerate(train_character_loader), total=len(train_character_loader), leave=True)\n",
    "    for j, train in loop:\n",
    "        X_train = train[0][0]\n",
    "        y_train = train[1][0]\n",
    "        morse_chr_optimizer.zero_grad()\n",
    "        if morse_chr_model.__class__.__name__ in [\"MorseLSTM\", \"MorseLSTM2\", \"MorseBatchedLSTM\", \"MorseBatchedLSTM2\"]:\n",
    "            morse_chr_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_chr_model(X_train)\n",
    "        single_loss = morse_chr_loss_function(y_pred, y_train)\n",
    "        single_loss.backward()\n",
    "        morse_chr_optimizer.step()\n",
    "        train_losses.append(single_loss.item())\n",
    "        # update progress bar\n",
    "        if j % 1000 == 0:\n",
    "            loop.set_description(f\"Epoch [{i+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=np.mean(train_losses))\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {np.mean(train_losses):6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model: \n",
    "    torch.save(morse_key_model.state_dict(), 'models/morse_char_model')\n",
    "else:\n",
    "    morse_key_model.load_state_dict(torch.load('models/morse_char_model', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_char_train = torch.empty(1,18).to(device)\n",
    "morse_chr_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(train_character_loader), total=len(train_character_loader))\n",
    "for j, train in loop:\n",
    "    with torch.no_grad():\n",
    "        X_chr = train[0][0]\n",
    "        pred_val = morse_chr_model(X_chr)\n",
    "        p_char_train = torch.cat([p_char_train, pred_val.reshape(1,18)])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_train = p_char_train[1:] # Remove garbge\n",
    "print(p_char_train.shape) # t -> chars(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post process\n",
    "  \n",
    "  - Move to CPU to ger chars(time)\n",
    "  - Transpose to get times(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_train_c = p_char_train.cpu() # t -> chars(t) on CPU\n",
    "p_char_train_t = torch.transpose(p_char_train_c, 0, 1).cpu() # c -> times(c) on CPU\n",
    "print(p_char_train_c.shape, p_char_train_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_alpha = label_df_chr[n_prev:].reset_index(drop=True)\n",
    "plt.figure(figsize=(50,4+0.5*len(morse_gen.alphabet)))\n",
    "plt.plot(l_alpha[x0:x1][\"chr\"]*(len(alphabet)+1)+2, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev, 0]*1.9, label='dit')\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev, 1]*1.9, label='dah')\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev, 2]*1.9 + 1.0, label='ele')\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev, 3]*1.9 + 1.0, label='chr')\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev, 4]*1.9 + 1.0, label='wrd')\n",
    "plt.plot(p_char_train_t[1][x0:x1]*0.9 + 2.0, label='c')\n",
    "plt.plot(p_char_train_t[2][x0:x1]*0.9 + 2.0, label='w')\n",
    "for i, a in enumerate(alphabet):\n",
    "    plt_a = plt.plot(p_char_train_t[i+4][x0:x1]*0.9 + 3.0 + i, label=a)\n",
    "    plt.plot(l_alpha[a][x0:x1]*0.5 + 3.0 + i, color=plt_a[0].get_color(), alpha=0.5)\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "### Test keying dataset and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teststr = \"AAAA USERS ARE USING EGGS AND GRAIN MONGO TEST MADAME WONDER WOMAN GOOD MAMA USSR WAS GREAT AAA\"\n",
    "test_keying_dataset = MorsekeyingDataset(morse_gen, device, -17, 132*5, 27*5, teststr, alphabet)\n",
    "test_keying_loader = torch.utils.data.DataLoader(test_keying_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the keying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_key_test = torch.empty(1,5).to(device)\n",
    "morse_key_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(test_keying_loader), total=len(test_keying_loader))\n",
    "for j, test in loop:\n",
    "    with torch.no_grad():\n",
    "        X_test = test[0]\n",
    "        pred_val = morse_key_model(X_test[0])\n",
    "        p_key_test = torch.cat([p_key_test, pred_val.reshape(1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first garbage sample\n",
    "p_key_test = p_key_test[1:]\n",
    "print(p_key_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sm_test = sm(p_key_test)\n",
    "p_sm_test[:,1] -= p_sm_test[:,0]\n",
    "p_sm_test[:,0] = p_sm_test[:,0]*2.0 - 0.25\n",
    "p_sm_test[:,2] -= 0.125\n",
    "p_sm_test[:,3] -= 0.125\n",
    "p_sm_test[:,4] -= 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_key_test[0:2])\n",
    "p_dits_t = p_sm_test[:,0].to('cpu').numpy()\n",
    "p_dahs_t = p_sm_test[:,1].to('cpu').numpy()\n",
    "p_eles_t = p_sm_test[:,2].to('cpu').numpy()\n",
    "p_chrs_t = p_sm_test[:,3].to('cpu').numpy()\n",
    "p_wrds_t = p_sm_test[:,4].to('cpu').numpy()\n",
    "\n",
    "signal_t = test_keying_dataset.get_signal()\n",
    "envelope_t = test_keying_dataset.get_envelope()\n",
    "label_df0_t = test_keying_dataset.get_labels0()\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal_t[x0+n_prev:x1+n_prev]*0.5, label=\"sig\")\n",
    "plt.plot(envelope_t[x0+n_prev:x1+n_prev]*0.9, label='env')\n",
    "plt.plot(p_dits_t[x0:x1]*0.9 + 1.0, label='dit')\n",
    "plt.plot(p_dahs_t[x0:x1]*0.9 + 1.0, label='dah')\n",
    "plt.plot(p_eles_t[x0:x1]*0.9 + 2.0, label='ele', color='orange')\n",
    "plt.plot(p_chrs_t[x0:x1]*0.9 + 2.0, label='chr')\n",
    "plt.plot(p_wrds_t[x0:x1]*0.9 + 2.0, label='wrd', color='green')\n",
    "plt.title(\"keying - predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test character dataset and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_character_dataset = MorseCharacterDataset(p_sm_test, label_df0_t[n_prev:].reset_index(drop=True), n_prev)\n",
    "test_character_loader = torch.utils.data.DataLoader(test_character_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the character model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_char_test = torch.empty(1,18).to(device)\n",
    "morse_chr_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(test_character_loader), total=len(test_character_loader))\n",
    "for j, test in loop:\n",
    "    with torch.no_grad():\n",
    "        X_chr = test[0][0]\n",
    "        pred_val = morse_chr_model(X_chr)\n",
    "        p_char_test = torch.cat([p_char_test, pred_val.reshape(1,18)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_test = p_char_test[1:] # Remove garbge\n",
    "print(p_char_test.shape) # t -> chars(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_test_c = p_char_test.cpu() # t -> chars(t) on CPU\n",
    "p_char_test_t = torch.transpose(p_char_test_c, 0, 1).cpu() # c -> times(c) on CPU\n",
    "print(p_char_test_c.shape, p_char_test_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_chr = test_character_dataset.get_X().cpu()\n",
    "label_df_chr_t = test_character_dataset.get_labels()\n",
    "l_alpha_t = label_df_chr_t[n_prev:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,4+0.5*len(morse_gen.alphabet)))\n",
    "plt.plot(l_alpha_t[:][\"chr\"]*(len(alphabet)+1)+2, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:, 0]*1.9, label='dit')\n",
    "plt.plot(X_test_chr[n_prev:, 1]*1.9, label='dah')\n",
    "plt.plot(X_test_chr[n_prev:, 2]*1.9 + 1.0, label='ele')\n",
    "plt.plot(X_test_chr[n_prev:, 3]*1.9 + 1.0, label='chr')\n",
    "plt.plot(X_test_chr[n_prev:, 4]*1.9 + 1.0, label='wrd')\n",
    "plt.plot(p_char_test_t[1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_char_test_t[2]*0.9 + 2.0, label='w', color=\"red\")\n",
    "for i, a in enumerate(alphabet):\n",
    "    plt_a = plt.plot(p_char_test_t[i+4,:]*0.9 + 3.0 + i, label=a)\n",
    "    plt.plot(l_alpha_t[a]*0.5 + 3.0 + i, color=plt_a[0].get_color(), linestyle=\"--\")\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gated by character prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(200,4+0.5*len(morse_gen.alphabet)))\n",
    "plt.plot(l_alpha_t[\"chr\"]*(len(alphabet)+1)+2, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:, 0], label='dit')\n",
    "plt.plot(X_test_chr[n_prev:, 1], label='dah')\n",
    "plt.plot(X_test_chr[n_prev:, 2] + 1.0, label='ele')\n",
    "plt.plot(X_test_chr[n_prev:, 3] + 1.0, label='chr')\n",
    "plt.plot(X_test_chr[n_prev:, 4] + 1.0, label='wrd')\n",
    "plt.plot(p_char_test_t[1]*0.9 + 2.0, label=\"cp\", color=\"green\")\n",
    "plt.plot(p_char_test_t[2]*0.9 + 2.0, label=\"wp\", color=\"red\")\n",
    "for i, a in enumerate(alphabet):\n",
    "    line_a = p_char_test_t[i+4] * p_char_test_t[1]\n",
    "    plt_a = plt.plot(line_a*0.9 + 3.0 + i, label=a)\n",
    "    plt.plot(l_alpha_t[a]*0.5 + 3.0 + i, color=plt_a[0].get_color(), linestyle=\"--\")\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted_gated.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedural decision making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoder:\n",
    "    def __init__(self, alphabet, chr_len, wrd_len):\n",
    "        self.nb_alpha = len(alphabet)\n",
    "        self.alphabet = alphabet\n",
    "        self.chr_len = chr_len\n",
    "        self.wrd_len = wrd_len\n",
    "        self.sums = [0.0 for x in range(self.nb_alpha+2)]\n",
    "        self.tests = [0.0 for x in range(self.nb_alpha+2)]\n",
    "        self.prevs = [0.0 for x in range(self.nb_alpha+2)]\n",
    "        self.counts = [0 for x in range(self.nb_alpha+2)]\n",
    "        self.res = \"\"\n",
    "\n",
    "    def new_samples(self, samples):\n",
    "        for i, s in enumerate(samples):\n",
    "            if i > 2:\n",
    "                t = s * samples[0] # gating for alpha characters\n",
    "            else:\n",
    "                t = s\n",
    "            if i > 0:\n",
    "                j = i-1\n",
    "                if t >= 0.5 and self.prevs[j] < 0.5:\n",
    "                    self.counts[j] = 0\n",
    "                if t > 0.5:\n",
    "                    self.sums[j] = self.sums[j] + t\n",
    "                    self.tests[j] = 0.0\n",
    "                else:\n",
    "                    blk_len = wrd_len if j == 0 else chr_len\n",
    "                    if self.counts[j] > blk_len:\n",
    "                        self.tests[j] = self.sums[j]\n",
    "                        self.sums[j] = 0.0\n",
    "                self.counts[j] += 1\n",
    "                self.prevs[j] = t\n",
    "        if np.sum(self.tests) > 0.0:\n",
    "            ci = np.argmax(self.tests)\n",
    "            if ci == 0:\n",
    "                self.res += \" \"\n",
    "            elif ci > 1:\n",
    "                self.res += self.alphabet[ci - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_len = round(samples_per_dit*2 / 128)\n",
    "wrd_len = round(samples_per_dit*4 / 128)\n",
    "decoder = MorseDecoder(alphabet, chr_len, wrd_len)\n",
    "for s in p_char_test_c:\n",
    "    decoder.new_samples(s[1:]) # c, w, n, [alpha]\n",
    "print(decoder.res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(samples_per_dit*4 / 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_l = p_char_test_t[1]\n",
    "test_sum = 0.0\n",
    "test_count = 0\n",
    "int_count = 0\n",
    "prev_avg = None\n",
    "res = []\n",
    "prev_avg = None\n",
    "for t in test_l:\n",
    "    if prev_avg is None:\n",
    "        prev_avg = t\n",
    "        test_sum = t\n",
    "        test_count = 1\n",
    "        continue\n",
    "    proxy_avg = (test_sum + t) / (test_count + 1)\n",
    "    if proxy_avg >= prev_avg:\n",
    "        avg = proxy_avg\n",
    "        test_count += 1\n",
    "        int_count = 0\n",
    "    else:\n",
    "        avg = t\n",
    "        prev_avg = 0\n",
    "        test_sum = t\n",
    "        test_count = 1\n",
    "        int_count += 1\n",
    "    if int_count < 5:\n",
    "        res.append(avg)\n",
    "    else:\n",
    "        res.append(0)\n",
    "    prev_avg = avg\n",
    "                \n",
    "plt.figure(figsize=(300,6))\n",
    "plt.plot(res, color=\"red\")\n",
    "plt.plot(test_l, color=\"green\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_l = p_char_test_t[1]\n",
    "test_l = p_char_test_t[5]\n",
    "test_sum = 0.0\n",
    "res = []\n",
    "gat = []\n",
    "for i, t in enumerate(test_l):\n",
    "    s = t * char_l[i]\n",
    "    gat.append(s)\n",
    "    if s > 0.5:\n",
    "        test_sum = test_sum + s\n",
    "        res.append(0)\n",
    "    else:\n",
    "        res.append(test_sum)\n",
    "        test_sum = 0.0\n",
    "                \n",
    "plt.figure(figsize=(300,6))\n",
    "plt.plot(res, color=\"red\")\n",
    "plt.plot(test_l, color=\"green\")\n",
    "plt.plot(gat, color=\"orange\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
