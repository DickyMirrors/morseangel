{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with element sequence recognition - 6 characters - value encoded prediction\n",
    "\n",
    "Builds on `RNN-Morse-chars-single-ddp06` with value encoded prediction. The sequence of elements is ternary encoded in reverse order relative to their position. The example below is for 3 elements (14 characters) encoding on ternary values. The rationale is that encoded characters with maximum similarity will have the minimal distance between them. For example:\n",
    "\n",
    "  - S `...`  is 13 and U `..-` is 14. \n",
    "  - I `..` is 12, A `.-` is 15, N `-.` is 21 thus relative position matters the maximum similarity being at the start of sequence.\n",
    "  - Conversely K `-.-` is 23 and R `.-.` is 16, \n",
    "  - E `.` is 9, T `-` is 18. \n",
    "  \n",
    "Extrema are E (9) and O (26). The shift by 9 can be corrected by subtracting 8 to positive values. Generally: 3^(max_ele-1) - 1\n",
    "\n",
    "| element   | pos0              | pos1             | pos2             |\n",
    "| --------- | ----------------- | ---------------- | ---------------- |\n",
    "| n/a (0)   | +0                | +0               | +0               |\n",
    "| dit (1)   | +3^2 (9)          | +3^1 (3)         | +3^0   (1)       |\n",
    "| dah (2)   | +2&times;3^2 (18) | +2&times;3^1 (6) | +2&times;3^0 (2) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create string\n",
    "\n",
    "Each character in the alphabet should happen a large enough number of times. As a rule of thumb we will take some multiple of the number of characters in the alphabet. If the multiplier is large enough the probability of each character appearance will be even over the alphabet. \n",
    "\n",
    "Seems to get better results looking at the gated graphs but procedural decision has to be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "\n",
    "morse_gen = MorseGen.Morse()\n",
    "alphabet = morse_gen.alphabet6\n",
    "print(132/len(alphabet))\n",
    "\n",
    "morsestr = MorseGen.get_morse_str(nchars=132*3, nwords=27*3, chars=alphabet)\n",
    "print(alphabet)\n",
    "print(len(morsestr), morsestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframe and extract envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 8000\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*12*2) + 1\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim_val(morsestr, samples_per_dit, 128, alphabet)\n",
    "env = label_df['env'].to_numpy()\n",
    "print(type(env), len(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_new_data(morse_gen, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "    if not phrase:\n",
    "        phrase = MorseGen.get_morse_str(nchars=nchars, nwords=nwords, chars=alphabet)\n",
    "    print(len(phrase), phrase)\n",
    "    Fs = 8000\n",
    "    samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "    n_prev = int((samples_per_dit/128)*19) + 1 # number of samples to look back is slightly more than a \"O\" a word space (3*4+7=19)\n",
    "    #n_prev = int((samples_per_dit/128)*27) + 1 # number of samples to look back is slightly more than a \"0\" a word space (5*4+7=27)\n",
    "    print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "    label_df = morse_gen.encode_df_decim_val(phrase, samples_per_dit, 128, alphabet)\n",
    "    # extract the envelope\n",
    "    envelope = label_df['env'].to_numpy()\n",
    "    # remove the envelope\n",
    "    label_df.drop(columns=['env'], inplace=True)\n",
    "    SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "    SNR_linear *= 256 # Apply original FFT\n",
    "    print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "    t = np.linspace(0, len(envelope)-1, len(envelope))\n",
    "    power = np.sum(envelope**2)/len(envelope)\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(envelope))\n",
    "    # noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "    signal = (envelope + noise)**2\n",
    "    signal[signal > 1.0] = 1.0 # a bit crap ...\n",
    "    return envelope, signal, label_df, n_prev, morse_gen.max_ele(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "envelope, signal, label_df, n_prev, max_ele = get_new_data(morse_gen, SNR_dB=-17, phrase=morsestr, alphabet=alphabet)\n",
    "\n",
    "# Show\n",
    "print(n_prev)\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "    \n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,20))\n",
    "plt.plot(signal[x0:x1]*0.7, label=\"sig\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 1.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 1.0, label='chr', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 1.0, label='wrd')\n",
    "plt.plot(label_df[x0:x1].val + 2.0, label='val')\n",
    "plt.title(\"signal and labels\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader\n",
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MorsekeyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, morse_gen, device, SNR_dB=-23, nchars=132, nwords=27, phrase=None, alphabet=\"ABC\"):\n",
    "        self.envelope, self.signal, self.label_df0, self.seq_len, self.max_ele = get_new_data(morse_gen, SNR_dB=SNR_dB, phrase=phrase, alphabet=alphabet)\n",
    "        self.label_df = self.label_df0\n",
    "        self.X = torch.FloatTensor(self.signal).to(device)\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_envelope(self):\n",
    "        return self.envelope\n",
    "    \n",
    "    def get_signal(self):\n",
    "        return self.signal\n",
    "    \n",
    "    def get_X(self):\n",
    "        return self.X\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_labels0(self):\n",
    "        return self.label_df0\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len()\n",
    "    \n",
    "    def max_ele(self):\n",
    "        return self.max_ele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keying data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_chr_dataset = MorsekeyingDataset(morse_gen, device, -20, 132*5, 27*5, morsestr, alphabet)\n",
    "train_chr_loader = torch.utils.data.DataLoader(train_chr_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = train_chr_dataset.get_signal()\n",
    "envelope = train_chr_dataset.get_envelope()\n",
    "label_df = train_chr_dataset.get_labels()\n",
    "label_df0 = train_chr_dataset.get_labels0()\n",
    "\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,4))\n",
    "plt.plot(signal[x0:x1]*0.8, label=\"sig\", color=\"cornflowerblue\")\n",
    "plt.plot(envelope[x0:x1]*0.9, label='env', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 1.0, label='ele', color=\"orange\")\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 1.0, label='chr', color=\"green\")\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 1.0, label='wrd', color=\"red\")\n",
    "plt.plot(label_df[x0:x1].val + 2.0, label='val', color=\"darkturquoise\")\n",
    "plt.title(\"keying - signal and labels\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseBatchedLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "    \n",
    "    def _minmax(self, x):\n",
    "        x -= x.min(0)[0]\n",
    "        x /= x.max(0)[0]\n",
    "        \n",
    "    def _hardmax(self, x):\n",
    "        x /= x.sum()\n",
    "        \n",
    "    def _sqmax(self, x):\n",
    "        x = x**2\n",
    "        x /= x.sum()\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        #print(len(input_seq), input_seq.shape, input_seq.view(-1, 1, 1).shape)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(-1, 1, self.input_size), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        self._sqmax(predictions[-1])\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )     \n",
    "    \n",
    "class MorseLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the keying model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_chr_model = MorseBatchedLSTM(device, hidden_layer_size=len(alphabet), output_size=4).to(device) # This is the only way to get things work properly with device\n",
    "morse_chr_loss_function = nn.MSELoss()\n",
    "morse_chr_optimizer = torch.optim.Adam(morse_chr_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_chr_model)\n",
    "print(morse_chr_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_chr_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand(n_prev)\n",
    "X_t = X_t.cuda()\n",
    "print(\"Input shape\", X_t.shape, X_t.view(-1, 1, 1).shape)\n",
    "print(X_t)\n",
    "morse_chr_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(morse_chr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_chr_loader)\n",
    "X, y = next(it)\n",
    "print(X.reshape(n_prev,1).shape, X[0].shape, y[0].shape)\n",
    "print(X[0], y[0])\n",
    "X, y = next(it)\n",
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epochs = 4\n",
    "morse_chr_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_losses = []\n",
    "    loop = tqdm(enumerate(train_chr_loader), total=len(train_chr_loader), leave=True)\n",
    "    for j, train in loop:\n",
    "        X_train = train[0][0]\n",
    "        y_train = train[1][0]\n",
    "        morse_chr_optimizer.zero_grad()\n",
    "        if morse_chr_model.__class__.__name__ in [\"MorseLSTM\", \"MorseLSTM2\", \"MorseBatchedLSTM\", \"MorseBatchedLSTM2\"]:\n",
    "            morse_chr_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_chr_model(X_train)\n",
    "        single_loss = morse_chr_loss_function(y_pred, y_train)\n",
    "        single_loss.backward()\n",
    "        morse_chr_optimizer.step()\n",
    "        train_losses.append(single_loss.item())\n",
    "        # update progress bar\n",
    "        if j % 1000 == 0:\n",
    "            loop.set_description(f\"Epoch [{i+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=np.mean(train_losses))\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {np.mean(train_losses):6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model: \n",
    "    torch.save(morse_chr_model.state_dict(), 'models/morse_a06_model')\n",
    "else:\n",
    "    morse_chr_model.load_state_dict(torch.load('models/morse_singlemm_model', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_char_train = torch.empty(1,4).to(device)\n",
    "morse_chr_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(train_chr_loader), total=len(train_chr_loader))\n",
    "for j, train in loop:\n",
    "    with torch.no_grad():\n",
    "        X_chr = train[0][0]\n",
    "        pred_val = morse_chr_model(X_chr)\n",
    "        p_char_train = torch.cat([p_char_train, pred_val.reshape(1,4)])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_train = p_char_train[1:] # Remove garbge\n",
    "print(p_char_train.shape) # t -> chars(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post process\n",
    "  \n",
    "  - Move to CPU to ger chars(time)\n",
    "  - Transpose to get times(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_char_train_c = p_char_train.cpu() # t -> chars(t) on CPU\n",
    "p_char_train_t = torch.transpose(p_char_train_c, 0, 1).cpu() # c -> times(c) on CPU\n",
    "print(p_char_train_c.shape, p_char_train_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chr = train_chr_dataset.X.cpu()\n",
    "label_df_chr = train_chr_dataset.get_labels()\n",
    "\n",
    "l_alpha = label_df_chr[n_prev:].reset_index(drop=True)\n",
    "plt.figure(figsize=(50,4))\n",
    "plt.plot(l_alpha[x0:x1][\"chr\"]*4, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_train_chr[x0+n_prev:x1+n_prev]*0.9, label='sig')\n",
    "plt.plot(p_char_train_t[0][x0:x1]*0.9 + 1.0, label='e', color=\"orange\")\n",
    "plt.plot(p_char_train_t[1][x0:x1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_char_train_t[2][x0:x1]*0.9 + 2.0, label='w', color=\"red\")\n",
    "plt.plot(p_char_train_t[3][x0:x1] + 3.0, label='v', color=\"purple\")\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "### Test dataset and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teststr = \"AA MA MINETTE TETA ET MA MAMA MINE AA\"\n",
    "test_chr_dataset = MorsekeyingDataset(morse_gen, device, -17, 132*5, 27*5, teststr, alphabet)\n",
    "test_chr_loader = torch.utils.data.DataLoader(test_chr_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test = torch.empty(1,max_ele+3).to(device)\n",
    "morse_chr_model.eval()\n",
    "\n",
    "loop = tqdm(enumerate(test_chr_loader), total=len(test_chr_loader))\n",
    "for j, test in loop:\n",
    "    with torch.no_grad():\n",
    "        X_test = test[0]\n",
    "        pred_val = morse_chr_model(X_test[0])\n",
    "        p_chr_test = torch.cat([p_chr_test, pred_val.reshape(1,max_ele+3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop first garbage sample\n",
    "p_chr_test = p_chr_test[1:]\n",
    "print(p_chr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test_c = p_chr_test.cpu() # t -> chars(t) on CPU\n",
    "p_chr_test_t = torch.transpose(p_chr_test_c, 0, 1).cpu() # c -> times(c) on CPU\n",
    "print(p_chr_test_c.shape, p_chr_test_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_chr = test_chr_dataset.X.cpu()\n",
    "label_df_t = test_chr_dataset.get_labels()\n",
    "l_alpha_t = label_df_t[n_prev:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,4))\n",
    "plt.plot(l_alpha_t[:][\"chr\"]*4, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:]*0.9, label='sig')\n",
    "plt.plot(p_chr_test_t[0]*0.9 + 1.0, label='e', color=\"purple\")\n",
    "plt.plot(p_chr_test_t[1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_chr_test_t[2]*0.9 + 2.0, label='w', color=\"red\")\n",
    "for i in range(max_ele):\n",
    "    plt_a = plt.plot(p_chr_test_t[i+3]*0.9 + 3.0, label=f'e{i}')\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_chr_test_tn = p_chr_test_t.numpy()\n",
    "ele_len = round(samples_per_dit / 256)\n",
    "win = np.ones(ele_len)/ele_len\n",
    "p_chr_test_tlp = np.apply_along_axis(lambda m: np.convolve(m, win, mode='full'), axis=1, arr=p_chr_test_tn)\n",
    "\n",
    "plt.figure(figsize=(100,4))\n",
    "plt.plot(l_alpha_t[:][\"chr\"]*4, label=\"ychr\", alpha=0.2, color=\"black\")\n",
    "plt.plot(X_test_chr[n_prev:]*0.9, label='sig')\n",
    "plt.plot(p_chr_test_tlp[0]*0.9 + 1.0, label='e', color=\"purple\")\n",
    "plt.plot(p_chr_test_tlp[1]*0.9 + 2.0, label='c', color=\"green\")\n",
    "plt.plot(p_chr_test_tlp[2]*0.9 + 2.0, label='w', color=\"red\")\n",
    "for i in range(max_ele):\n",
    "    plt.plot(p_chr_test_tlp[i+3,:]*0.9 + 3.0, label=f'e{i}')\n",
    "plt.title(\"predictions\")\n",
    "plt.legend(loc=2)\n",
    "plt.grid()\n",
    "plt.savefig('img/predicted.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gated by character prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedural decision making TBD\n",
    "\n",
    "### take 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoder2:\n",
    "    def __init__(self, alphabet, chr_len, wrd_len):\n",
    "        self.nb_alpha = len(alphabet)\n",
    "        self.alphabet = alphabet\n",
    "        self.chr_len = chr_len\n",
    "        self.wrd_len = wrd_len // 2\n",
    "        self.threshold = 0.25\n",
    "        self.chr_count = 0\n",
    "        self.wrd_count = 0        \n",
    "        self.prevs = [0.0 for x in range(self.nb_alpha+3)]\n",
    "        self.res = \"\"\n",
    "    \n",
    "    def new_samples(self, samples):\n",
    "        for i, s in enumerate(samples): # c, w, n, [alpha]\n",
    "            if i > 1:\n",
    "                t = s * samples[0] # gating for alpha characters\n",
    "            else:\n",
    "                t = s\n",
    "            if i == 1: # word separator\n",
    "                if t >= self.threshold and self.prevs[1] < self.threshold and self.wrd_count == 0:\n",
    "                    self.wrd_count = self.wrd_len\n",
    "                    self.res += \" \"\n",
    "            elif i > 1: # characters\n",
    "                if t >= self.threshold and self.prevs[i] < self.threshold and self.chr_count == 0:\n",
    "                    self.chr_count = self.chr_len\n",
    "                    if i > 2:\n",
    "                        self.res += self.alphabet[i-3]\n",
    "            self.prevs[i] = t\n",
    "        if self.wrd_count > 0:\n",
    "            self.wrd_count -= 1\n",
    "        if self.chr_count > 0:\n",
    "            self.chr_count -= 1                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_len = round(samples_per_dit*2 / 128)\n",
    "wrd_len = round(samples_per_dit*4 / 128)\n",
    "decoder = MorseDecoder2(alphabet, chr_len, wrd_len)\n",
    "#p_chr_test_clp = torch.transpose(p_chr_test_tlp, 0, 1)\n",
    "p_chr_test_clp = p_chr_test_tlp.transpose()\n",
    "for s in p_chr_test_clp:\n",
    "    decoder.new_samples(s[1:]) # c, w, n, [alpha]\n",
    "print(decoder.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseDecoder1:\n",
    "    def __init__(self, alphabet, chr_len, wrd_len):\n",
    "        self.nb_alpha = len(alphabet)\n",
    "        self.alphabet = alphabet\n",
    "        self.chr_len = chr_len\n",
    "        self.wrd_len = wrd_len\n",
    "        self.alpha = 0.3\n",
    "        self.threshold = 0.45\n",
    "        self.accum = [0.0 for x in range(self.nb_alpha+2)] \n",
    "        self.sums = [0.0 for x in range(self.nb_alpha+2)]\n",
    "        self.tests = [0.0 for x in range(self.nb_alpha+2)]\n",
    "        self.prevs = [0.0 for x in range(self.nb_alpha+2)]\n",
    "        self.counts = [0 for x in range(self.nb_alpha+2)]\n",
    "        self.res = \"\"\n",
    "\n",
    "    def new_samples(self, samples):\n",
    "        for i, s in enumerate(samples):\n",
    "            if i > 2:\n",
    "                t = s * samples[0] # gating for alpha characters\n",
    "            else:\n",
    "                t = s\n",
    "#             t = s\n",
    "            if i > 0:\n",
    "                j = i-1\n",
    "                t = self.alpha * t + (1 - self.alpha) * self.accum[j] # Exponential average does the low pass filtering\n",
    "                self.accum[j] = t\n",
    "                if t >= self.threshold and self.prevs[j] < self.threshold:\n",
    "                    self.counts[j] = 0\n",
    "                if t > self.threshold:\n",
    "                    self.sums[j] = self.sums[j] + t\n",
    "                    self.tests[j] = 0.0\n",
    "                else:\n",
    "                    blk_len = wrd_len if j == 0 else chr_len\n",
    "                    if self.counts[j] > blk_len:\n",
    "                        self.tests[j] = self.sums[j]\n",
    "                        self.sums[j] = 0.0\n",
    "                self.counts[j] += 1\n",
    "                self.prevs[j] = t\n",
    "        if np.sum(self.tests) > 0.0:\n",
    "            ci = np.argmax(self.tests)\n",
    "            if ci == 0:\n",
    "                self.res += \" \"\n",
    "            elif ci > 1:\n",
    "                self.res += self.alphabet[ci - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_len = round(samples_per_dit*2 / 128)\n",
    "wrd_len = round(samples_per_dit*4 / 128)\n",
    "decoder = MorseDecoder1(alphabet, chr_len, wrd_len)\n",
    "for s in p_chr_test_c:\n",
    "    decoder.new_samples(s[1:]) # c, w, n, [alpha]\n",
    "print(decoder.res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
